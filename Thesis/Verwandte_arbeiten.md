\chapter{Verwandte Arbeiten}

In diesem Kapitel werden verwandte Arbeiten zum Thema ``Named Entity Recognition with Weakly Labelled Data'' vorgestellt. Dabei werden verschiedene Ansätze und Methoden untersucht, die in der Literatur bereits zu diesem Thema vorgestellt wurden. Der Fokus wird dabei auf Ansätze liegen, die sich mit der Verwendung von schwach gekennzeichneten Daten befassen, um NER zu verbessern. Es wird gezeigt, welche Herausforderungen bei der Verwendung von schwach gekennzeichneten Daten auftreten und wie diese Herausforderungen von verschiedenen Ansätzen angegangen werden. %Zudem werden die Ergebnisse der verwandten Arbeiten verglichen und analysiert, um die Stärken und Schwächen der verschiedenen Ansätze zu identifizieren.

Es wurden verschiedene Arbeiten untersucht zum Thema NER mit schwach annotierten Daten. Die Auswahl der Arbeiten erfolgte durch eine umfassende Literatursuche in wissenschaftlichen Datenbanken wie Google Scholar \cite{google_scholar}, ACM Digital Library \cite{acm} und Connected Papers \cite{connected_papers}.

Als Kriterien für die Auswahl der Arbeiten dienten die Relevanz des Themas, die Verwendung von schwach gekennzeichneten Daten und die Ergebnisse, die in Bezug auf NER erzielt wurden. Es wurde keine Arbeit von vor 2018 verwendet. 
%Die ausgewählten Arbeiten wurden nach verwendeten Methoden und Ansätzen gruppiert und in einer tabellarischen Übersicht zusammengefasst.

%Die Evaluationsmetriken, die in den verwandten Arbeiten verwendet wurden, umfassten F1-Score, Precision, Recall und Accuracy. Die Ergebnisse der verwandten Arbeiten wurden anhand dieser Metriken verglichen, um die Stärken und Schwächen der verschiedenen Ansätze zu identifizieren.

\\~\\
Giorgi et .al \cite{giorgi_transfer_2018} hat gezeigt, dass das Vor-Trainieren eines BiLSTM-CRF-Modells auf einem ``Silber-Standard'' -Korpus von 50.000 Abstracts, die von automatischen Annotationen anstatt von menschlichen Experten für biomedizinische Entitäten annotiert wurden, die Leistung bei NER-Aufgaben, die weniger als 6.000 Trainingsbeispiele haben, verbessern kann.
\\~\\
Die Arbeit von Weber und Huner \cite{weber_huner_2020} zeigt eine Erweiterung der vorherigen Methode zur Bekämpfung des Problem der geringen Verfügbarkeit von Trainingsdaten bei NER mit schwach gekennzeichneten Daten. Sie evaluieren verschiedene Methoden, indem sie zunächst ein tiefes Neuronales Netz (LSTM-CRF) vortrainieren und anschließend eine kurze Fine-Tuning-Phase auf eine bestimmten Textsammlung konzentrieren. Im Vergleich zur vorherigen Methode unterscheidet sie sich dadurch, dass sie unterschiedliche Vortrainingsansätze verwenden.
\\~\\
Gao et al. \cite{gao_pre-training_2021}  untersuchen die Wirksamkeit von Transferlernen und semi-supervised Selbstlernen, um die Leistung von NER-Modellen in biomedizinischen Domänen mit sehr begrenzten beschrifteten Daten (250-2000 beschriftete Beispiele) zu verbessern. Sie trainieren zunächst ein BiLSTM-CRF und ein BERT-Modell - unter anderem mit JNLBPA - und wenden Fine-Tuning an um die Modelle dann auf eine spezifischere NER-Aufgabe mit sehr begrenzten Trainingsdaten zu trainieren. Schließlich wenden sie semi-supervised Selbstlernen mit nicht annotierten Daten an, um die Modellleistungen weiter zu verbessern. Sie haben gezeigt, dass Transferlernen in Szenarien mit sehr wenigen beschrifteten Sätzen entscheidend ist, um die Modellleistung auf ein Niveau zu bringen, bei dem Selbstlernen wirksam sein kann.
\\~\\
In der Arbeit von Roy et al. \cite{roy_attribute_2021} wurde eine seq2seq-Methode für die NER Aufgabe mit schwach gekennzeichneten Daten verwendet. Dabei wurde das T5-Modell genutzt, um das NER-Problem als Fragebeantwortungsaufgabe zu definieren. Es konnte eine verbesserte Leistung im Vergleich zu anderen Benchmark-Datensätzen in ihrem Anwendungsbereich gezeigt werden. Allerdings wurde der Ansatz nicht auf einen Datensatz im biomedizinischen Bereich, sondern nur im Bereich des E-Commerce getestet.
\\~\\
In der Arbeit von Jiang et al. \cite{jiang_named_2021} wurde ein mehrstufiger Ansatz vorgestellt, bei dem ein Modell erst auf unbeschrifteten Daten trainiert wird. In der zweiten Phase werden Wissensbasen genutzt, um die unbeschrifteten Daten der Zieldomäne in schwach gekennzeichnete Daten zu wandeln. Anschließend wird ein weiteres kontinuierliches Pre-Training sowohl für die schwach als auch für die stark gekennzeichneten Daten durchgeführt. Hierbei wird das von Jiang et al. vorgeschlagene Verfahren zur Vervollständigung der schwachen Kennzeichnung und die Noise-Aware Verlustfunktion verwendet, um die ``Unvollständigkeit'' und das \singlequote Noisy Labeling \singlequote der schwachen Kennzeichnungen effektiv zu behandeln. In der dritten Phase wird das Modell erneut mit Fine-Tuning auf den stark gekennzeichneten Daten erneuert. Das Fine-Tuning auf stark gekennzeichneten Daten ist hierbei von entscheidender Bedeutung. Jiang et al. haben ihren Ansatz auch im biomedizinischen Bereich angewendet, jedoch nicht auf Basis des JNLPBA-Datensatzes und liefern keine Leistungsmessung für ein Modell, das nur auf schwach gekennzeichneten Daten trainiert wurde und verwenden nicht T5.
\\~\\
In dieser Bachelorarbeit wird die Leistung eines Fine-Tune T5-Modells untersucht, um auf die Erkenntnisse von Roy et al. aufzubauen. Das Modell wird mit einem biomedizinischen Datensatz, dem JNLPBA-Datensatz, trainiert. Der JNLPBA-Datensatz enthält Textdokumente aus der Biomedizin, die für NER annotiert wurden.

Das Ziel der Arbeit ist es, zu untersuchen, wie gut das T5-Modell in der Lage ist, Entitäten in biomedizinischen, speziell JNLPBA zu erkennen. Um dies zu erreichen, werden sowohl stark annotierte als auch schwach annotierte Daten verwendet. Der schwache Datensatz enthält Texte, die in einem eigenen Verfahren schwach annotiert wurden.

Das T5-Modell wird auf beiden Datensätzen trainiert und die Ergebnisse werden verglichen, um zu sehen, wie gut das Modell auf schwach annotierten Daten abschneidet im Vergleich zu stark annotierten Daten. Zusätzlich wird der seq2seq-Ansatz mit einer Tokenklassifizierung mithilfe des Bert-Base-Cased-Modells, das ebenfalls auf stark und schwach annotierten Daten trainiert wurde, verglichen.
