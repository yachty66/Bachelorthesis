{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! rm /home/jupyter/.cache/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nfliMbD5nexS",
    "outputId": "81958773-17d8-47a2-a477-439a53d235f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Sun Feb 12 08:45:51 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   47C    P0    27W /  70W |   1397MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     20182      C   /opt/conda/bin/python3.7         1395MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SymgaR13Uh8R",
    "outputId": "d66f03ba-4507-473d-ec7e-e1c09fdc8f68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.25.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.11.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (5.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.8.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.11.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: pytorch_lightning in /opt/conda/lib/python3.7/site-packages (1.9.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (1.12.1+cu113)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (0.11.0)\n",
      "Requirement already satisfied: packaging>=17.1 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (22.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (1.21.6)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (2022.11.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.4.2 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (0.5.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.7/site-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.28.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from lightning-utilities>=0.4.2->pytorch_lightning) (5.1.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.1.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.2)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (0.13.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.0.0->lightning-utilities>=0.4.2->pytorch_lightning) (3.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.26.13)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (0.1.97)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (2.8.0)\n",
      "Requirement already satisfied: seqeval in /opt/conda/lib/python3.7/site-packages (1.2.2)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (5.1.0)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.11.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.21.6)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (2022.11.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (7.0.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: dill<0.3.7 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.7/site-packages (from seqeval) (1.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2022.6)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.7/site-packages (0.13.8)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.7/site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (8.1.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from wandb) (65.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.28.1)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.7/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.12.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from wandb) (4.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.19.6)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.9.3)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.1.29)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (5.1.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (3.11.0)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (3.8.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->nltk) (5.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install pytorch_lightning\n",
    "!pip install sentencepiece datasets seqeval\n",
    "!pip install wandb\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GocN6aLfUZ5F",
    "outputId": "20754726-42e0-498d-afdb-90bf15c8acd9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/maxhager/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AdamW,\n",
    "    MT5ForConditionalGeneration,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    AutoTokenizer,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from datasets import load_dataset, load_metric\n",
    "from datasets import DatasetDict\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import re\n",
    "from itertools import chain\n",
    "from string import punctuation\n",
    "import wandb\n",
    "from wandb import AlertLevel\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "agRYwon4vgW4",
    "outputId": "d2fa6a81-a7d2-4cab-c4c7-991e861190d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmaxhager28\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/maxhager/Projects2023/BachelorThesis/Fine_tune/final/wandb/run-20230218_161627-2ufp19hc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/maxhager28/Bachelor_Thesis/runs/2ufp19hc\" target=\"_blank\">Seq2seq_jnlpba_test</a></strong> to <a href=\"https://wandb.ai/maxhager28/Bachelor_Thesis\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/maxhager28/Bachelor_Thesis/runs/2ufp19hc?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x173179cc0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"Bachelor_Thesis\", entity=\"maxhager28\", name=\"Seq2seq_jnlpba_test\")\n",
    "#wandb_logger = WandbLogger(project=\"Bachelor_Thesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jrjLi0gxUZ5H"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ct0QUX4HUZ5I"
   },
   "source": [
    "### Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4bi0ipHiZ3OK"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "class T5FineTuner(pl.LightningModule):\n",
    "        def __init__(self, hparam):\n",
    "            super(T5FineTuner, self).__init__()\n",
    "            self.hparam = hparam\n",
    "            self.model = T5ForConditionalGeneration.from_pretrained(\n",
    "                hparam.model_name_or_path\n",
    "            )\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(hparam.model_name_or_path)\n",
    "            self.save_hyperparameters()\n",
    "            self.true = []\n",
    "            self.pred = []\n",
    "            self.batch_counter = 0\n",
    "            #self.counter = 0\n",
    "\n",
    "        def is_logger(self):\n",
    "            return True\n",
    "\n",
    "        def label_true(self, incoming, actual):\n",
    "            l_targets = [\n",
    "                [tuple_list[0] for tuple_list in sublist] for sublist in actual\n",
    "            ]\n",
    "            l_predictions = []\n",
    "            for x in incoming:\n",
    "                result = re.split(\";(?![^\\(]*\\))\", x)\n",
    "                result = [x.strip() for x in result]\n",
    "                l_predictions.append([{e.split(\":\")[0].strip(): e.split(\":\")[1].strip()} for e in result if e])\n",
    "            result = []\n",
    "            for inner_list in l_targets:\n",
    "                outcome_inner = []\n",
    "                for word in inner_list:\n",
    "                    found = False\n",
    "                    for dict_list in l_predictions:\n",
    "                        for dict_item in dict_list:\n",
    "                            if word.lower() in dict_item.values():\n",
    "                                outcome_inner.append(list(dict_item.keys())[0])\n",
    "                                found = True\n",
    "                                break\n",
    "                        if found:\n",
    "                            break\n",
    "                    if not found:\n",
    "                        outcome_inner.append(\"O\")\n",
    "                result.append(outcome_inner)\n",
    "            print(\"label true inside\")\n",
    "            print(\"incoming\")\n",
    "            print(incoming)\n",
    "            print(30*\"-\")\n",
    "            print(\"l_targets\")\n",
    "            print(l_targets)\n",
    "            print(30*\"-\")\n",
    "            print(\"l_predictions\")\n",
    "            print(l_predictions)\n",
    "            print(30*\"-\")\n",
    "            print(\"result\")\n",
    "            print(result)\n",
    "            print(30*\"-\")\n",
    "            return result\n",
    "\n",
    "        def label_pred(self, incoming, actual):\n",
    "            l_targets = [\n",
    "                [tuple_list[0] for tuple_list in sublist] for sublist in actual\n",
    "            ]\n",
    "            l_predictions = []\n",
    "            for string in incoming:\n",
    "                matches = [\n",
    "                    match\n",
    "                    for match in re.findall(\n",
    "                        r\"(rna: (.+?))(;|$)|(dna: (.+?))(;|$)|(cell_line: (.+?))(;|$)|(protein: (.+?))(;|$)|(cell_type: (.+?))(;|$)\",\n",
    "                        string,\n",
    "                    )\n",
    "                    if match[1] or match[4] or match[7] or match[10] or match[13]\n",
    "                ]\n",
    "                inner_list = []\n",
    "                for match in matches:\n",
    "                    if match[1]:\n",
    "                        inner_list.append({\"rna\": match[1]})\n",
    "                    if match[4]:\n",
    "                        inner_list.append({\"dna\": match[4]})\n",
    "                    if match[7]:\n",
    "                        inner_list.append({\"cell_line\": match[7]})\n",
    "                    if match[10]:\n",
    "                        inner_list.append({\"protein\": match[10]})\n",
    "                    if match[13]:\n",
    "                        inner_list.append({\"cell_type\": match[13]})\n",
    "                l_predictions.append(inner_list)\n",
    "\n",
    "            result = []\n",
    "            for inner_list in l_targets:\n",
    "                outcome_inner = []\n",
    "                for word in inner_list:\n",
    "                    found = False\n",
    "                    for dict_list in l_predictions:\n",
    "                        for dict_item in dict_list:\n",
    "                            if word.lower() in dict_item.values():\n",
    "                                outcome_inner.append(list(dict_item.keys())[0])\n",
    "                                found = True\n",
    "                                break\n",
    "                        if found:\n",
    "                            break\n",
    "                    if not found:\n",
    "                        outcome_inner.append(\"O\")\n",
    "                result.append(outcome_inner)\n",
    "            return result\n",
    "\n",
    "        def forward(\n",
    "            self,\n",
    "            input_ids,\n",
    "            attention_mask=None,\n",
    "            decoder_input_ids=None,\n",
    "            decoder_attention_mask=None,\n",
    "            lm_labels=None,\n",
    "        ):\n",
    "            return self.model(\n",
    "                input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                decoder_input_ids=decoder_input_ids,\n",
    "                decoder_attention_mask=decoder_attention_mask,\n",
    "                labels=lm_labels,\n",
    "            )\n",
    "\n",
    "        def _step(self, batch):            \n",
    "            lm_labels = batch[\"target_ids\"]\n",
    "            lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "            outputs = self(\n",
    "                input_ids=batch[\"source_ids\"],\n",
    "                attention_mask=batch[\"source_mask\"],\n",
    "                lm_labels=lm_labels,\n",
    "                decoder_attention_mask=batch[\"target_mask\"],\n",
    "            )\n",
    "            loss = outputs[0]\n",
    "            return loss\n",
    "\n",
    "        def training_step(self, batch, batch_idx):\n",
    "            loss = self._step(batch)\n",
    "            self.log(\"loss\", loss)\n",
    "            wandb.log({\"train_loss_step\": loss})\n",
    "            return {\"loss\": loss}\n",
    "\n",
    "        def training_epoch_end(self, outputs):\n",
    "            avg_train_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "            tensorboard_logs = {\"avg_train_loss\": avg_train_loss}\n",
    "            wandb.log({\"avg_train_loss\": avg_train_loss})\n",
    "\n",
    "        def map_tags(self, lst):\n",
    "            mapping = {\n",
    "                \"O\": 0,\n",
    "                \"rna\": 1,\n",
    "                \"dna\": 2,\n",
    "                \"cell_line\": 3,\n",
    "                \"cell_type\": 4,\n",
    "                \"protein\": 5,\n",
    "            }\n",
    "            result = [[mapping[tag] for tag in tags] for tags in lst]\n",
    "            return result\n",
    "\n",
    "        def val_preprocessing(self, true, pred):\n",
    "            new_true = []\n",
    "            new_pred = []\n",
    "            for i in range(len(true)):\n",
    "                if true[i] == 0 and pred[i] == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    new_true.append(true[i])\n",
    "                    new_pred.append(pred[i])\n",
    "            return new_true, new_pred\n",
    "            \n",
    "        def validation_step(self, batch, batch_idx):\n",
    "            if batch_idx == 0:\n",
    "                self.batch_counter = 0\n",
    "            print(\"batch ids\")\n",
    "            print(batch_idx)\n",
    "            print(30*\"-\")\n",
    "            outputs = []\n",
    "            targets = []\n",
    "            all_text = []\n",
    "            true_labels = []\n",
    "            pred_labels = []\n",
    "            predictions = []\n",
    "            predictions_temp = []\n",
    "            l_true_labels = []\n",
    "            l_pred_labels = []\n",
    "            input_ids = batch[\"source_ids\"].to(\"cpu\")\n",
    "            attention_mask = batch[\"source_mask\"].to(\"cpu\")\n",
    "            outs = model.model.generate(\n",
    "                input_ids=input_ids, attention_mask=attention_mask\n",
    "            )\n",
    "            dec = [\n",
    "                tokenizer.decode(\n",
    "                    ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "                ).strip()\n",
    "                for ids in outs\n",
    "            ]\n",
    "            print(\"dec\")\n",
    "            print(dec)\n",
    "            print(30*\"-\")\n",
    "            target = [\n",
    "                tokenizer.decode(\n",
    "                    ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "                ).strip()\n",
    "                for ids in batch[\"target_ids\"]\n",
    "            ]\n",
    "            print(\"target\")\n",
    "            print(target)\n",
    "            print(30*\"-\")\n",
    "            texts = [\n",
    "                tokenizer.decode(\n",
    "                    ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "                ).strip()\n",
    "                for ids in batch[\"source_ids\"]\n",
    "            ]\n",
    "            print(\"text not stripped\")\n",
    "            text = [\n",
    "                tokenizer.decode(\n",
    "                    ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "                ).strip()\n",
    "                for ids in batch[\"source_ids\"]\n",
    "            ]\n",
    "            print(text)\n",
    "            print(30*\"-\")\n",
    "            print(\"text\")\n",
    "            print(texts)\n",
    "            print(30*\"-\")\n",
    "            print(\"token length\")\n",
    "            print(len(batch[\"tokens\"]))\n",
    "            len_source_ids = len(batch[\"source_ids\"])\n",
    "            print(\"tokens length\")\n",
    "            print(len(batch[\"tokens\"][self.batch_counter: self.batch_counter + len_source_ids]))\n",
    "            print(\"source ids length\")\n",
    "            print(len(batch[\"source_ids\"]))\n",
    "            print(\"target_ids length\")\n",
    "            print(len(batch[\"target_ids\"]))\n",
    "            print(\"self batch counter\")\n",
    "            print(self.batch_counter)\n",
    "            print(\"self batch counter + len source ids\")\n",
    "            print(self.batch_counter + len_source_ids)\n",
    "            print(30*\"-\")\n",
    "            true_label = self.label_true(target, batch[\"tokens\"][self.batch_counter: self.batch_counter + len_source_ids])\n",
    "            predicted_label = self.label_pred(dec, batch[\"tokens\"][self.batch_counter: self.batch_counter + len_source_ids])\n",
    "            self.batch_counter += len_source_ids\n",
    "            #self.counter += self.hparam.eval_batch_size \n",
    "            pred_mapped = self.map_tags(predicted_label)\n",
    "            true_mapped = self.map_tags(true_label)\n",
    "            self.true.extend(np.array(true_mapped).flatten())\n",
    "            self.pred.extend(np.array(pred_mapped).flatten())\n",
    "            val_loss = self._step(batch)\n",
    "            self.log(\"val_loss\", val_loss)\n",
    "            ##################################################################\n",
    "            print(\"true_label\")\n",
    "            print(true_label)\n",
    "            print(\"predicted_label\")\n",
    "            print(predicted_label)\n",
    "            if true_label == [] and predicted_label == []:\n",
    "                return\n",
    "            true_label = np.concatenate(true_mapped)\n",
    "            predicted_label = np.concatenate(pred_mapped)\n",
    "            print(\"true_label epoch end\")\n",
    "            print(true_label)\n",
    "            print(30*\"-\")\n",
    "            print(\"predicted_label epoch end\")\n",
    "            print(predicted_label)\n",
    "            print(30*\"-\")\n",
    "            true_label, predicted_label = self.val_preprocessing(true_label, predicted_label)\n",
    "            print(\"processed rue_label epoch end\")\n",
    "            print(true_label)\n",
    "            print(30*\"-\")\n",
    "            print(\"processed predicted_label epoch end\")\n",
    "            print(predicted_label)\n",
    "            print(30*\"-\")\n",
    "            cm = confusion_matrix(true_label, predicted_label)\n",
    "            cm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "            plt.imshow(cm, cmap=\"Blues\")\n",
    "            plt.title(\"Confusion Matrix\")\n",
    "            plt.xlabel(\"Predicted\")\n",
    "            plt.ylabel(\"True\")\n",
    "            plt.colorbar()\n",
    "            mapping = {\n",
    "                \"O\": 0,\n",
    "                \"rna\": 1,\n",
    "                \"dna\": 2,\n",
    "                \"cell_line\": 3,\n",
    "                \"cell_type\": 4,\n",
    "                \"protein\": 5,\n",
    "            }\n",
    "            reverse_mapping = {v: k for k, v in mapping.items()}\n",
    "            ax = plt.gca()\n",
    "            ax.set_xticks([i for i in range(len(mapping))])\n",
    "            ax.set_yticks([i for i in range(len(mapping))])\n",
    "            ax.set_xticklabels([reverse_mapping[i] for i in range(len(mapping))])\n",
    "            ax.set_yticklabels([reverse_mapping[i] for i in range(len(mapping))])\n",
    "            wandb.log({\"confusion_matrix\": wandb.Image(plt)})\n",
    "            plt.clf()\n",
    "            accuracy = accuracy_score(true_label, predicted_label)\n",
    "            precision, recall, fscore, support = precision_recall_fscore_support(\n",
    "                true_label, predicted_label, zero_division=1, average=\"weighted\"\n",
    "            )\n",
    "            wandb.log(\n",
    "                {\n",
    "                    \"precision\": precision,\n",
    "                    \"recall\": recall,\n",
    "                    \"f1\": fscore,\n",
    "                    \"accuracy\": accuracy,\n",
    "                }\n",
    "            )    \n",
    "            return {\"val_loss\": val_loss}        \n",
    "\n",
    "        def validation_epoch_end(self, outputs):\n",
    "            pass\n",
    "            '''self.counter = 0\n",
    "            true_label = np.concatenate(self.true)\n",
    "            predicted_label = np.concatenate(self.pred)\n",
    "            print(\"true_label epoch end\")\n",
    "            print(true_label)\n",
    "            print(30*\"-\")\n",
    "            print(\"predicted_label epoch end\")\n",
    "            print(predicted_label)\n",
    "            print(30*\"-\")\n",
    "            true_label, predicted_label = self.val_preprocessing(true_label, predicted_label)\n",
    "            print(\"processed rue_label epoch end\")\n",
    "            print(true_label)\n",
    "            print(30*\"-\")\n",
    "            print(\"processed predicted_label epoch end\")\n",
    "            print(predicted_label)\n",
    "            print(30*\"-\")\n",
    "            cm = confusion_matrix(true_label, predicted_label)\n",
    "            cm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "            plt.imshow(cm, cmap=\"Blues\")\n",
    "            plt.title(\"Confusion Matrix\")\n",
    "            plt.xlabel(\"Predicted\")\n",
    "            plt.ylabel(\"True\")\n",
    "            plt.colorbar()\n",
    "            mapping = {\n",
    "                \"O\": 0,\n",
    "                \"rna\": 1,\n",
    "                \"dna\": 2,\n",
    "                \"cell_line\": 3,\n",
    "                \"cell_type\": 4,\n",
    "                \"protein\": 5,\n",
    "            }\n",
    "            reverse_mapping = {v: k for k, v in mapping.items()}\n",
    "            ax = plt.gca()\n",
    "            ax.set_xticks([i for i in range(len(mapping))])\n",
    "            ax.set_yticks([i for i in range(len(mapping))])\n",
    "            ax.set_xticklabels([reverse_mapping[i] for i in range(len(mapping))])\n",
    "            ax.set_yticklabels([reverse_mapping[i] for i in range(len(mapping))])\n",
    "            wandb.log({\"confusion_matrix\": wandb.Image(plt)})\n",
    "            plt.clf()\n",
    "            accuracy = accuracy_score(true_label, predicted_label)\n",
    "            precision, recall, fscore, support = precision_recall_fscore_support(\n",
    "                true_label, predicted_label, zero_division=1, average=\"weighted\"\n",
    "            )\n",
    "            wandb.log({'precision': precision, 'recall': recall, 'f1': fscore, 'accuracy': accuracy})'''\n",
    "\n",
    "        def configure_optimizers(self):\n",
    "            model = self.model\n",
    "            no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "            optimizer_grouped_parameters = [\n",
    "                {\n",
    "                    \"params\": [\n",
    "                        p\n",
    "                        for n, p in model.named_parameters()\n",
    "                        if not any(nd in n for nd in no_decay)\n",
    "                    ],\n",
    "                    \"weight_decay\": self.hparam.weight_decay,\n",
    "                },\n",
    "                {\n",
    "                    \"params\": [\n",
    "                        p\n",
    "                        for n, p in model.named_parameters()\n",
    "                        if any(nd in n for nd in no_decay)\n",
    "                    ],\n",
    "                    \"weight_decay\": 0.0,\n",
    "                },\n",
    "            ]\n",
    "            optimizer = AdamW(\n",
    "                optimizer_grouped_parameters,\n",
    "                lr=self.hparam.learning_rate,\n",
    "                eps=self.hparam.adam_epsilon,\n",
    "            )\n",
    "            self.opt = optimizer\n",
    "            return [optimizer]\n",
    "\n",
    "        def optimizer_step(\n",
    "            self,\n",
    "            epoch=None,\n",
    "            batch_idx=None,\n",
    "            optimizer=None,\n",
    "            optimizer_idx=None,\n",
    "            optimizer_closure=None,\n",
    "            on_tpu=None,\n",
    "            using_native_amp=None,\n",
    "            using_lbfgs=None,\n",
    "        ):\n",
    "            optimizer.step(closure=optimizer_closure)\n",
    "            optimizer.zero_grad()\n",
    "            self.lr_scheduler.step()\n",
    "\n",
    "        def get_tqdm_dict(self):\n",
    "            tqdm_dict = {\n",
    "                \"loss\": \"{:.3f}\".format(self.trainer.avg_loss),\n",
    "                \"lr\": self.lr_scheduler.get_last_lr()[-1],\n",
    "            }\n",
    "            return tqdm_dict\n",
    "\n",
    "        def train_dataloader(self):\n",
    "            train_dataset = get_dataset(\n",
    "                tokenizer=self.tokenizer, type_path=\"train\", args=self.hparam\n",
    "            )\n",
    "            dataloader = DataLoader(\n",
    "                train_dataset,\n",
    "                batch_size=self.hparam.train_batch_size,\n",
    "                drop_last=True,\n",
    "                shuffle=True,\n",
    "                num_workers=2,\n",
    "            )\n",
    "            t_total = (\n",
    "                (\n",
    "                    len(dataloader.dataset)\n",
    "                    // (\n",
    "                        self.hparam.train_batch_size\n",
    "                        * max(1, self.hparam.n_gpu if torch.cuda.is_available() else 1)\n",
    "                    )\n",
    "                )\n",
    "                // self.hparam.gradient_accumulation_steps\n",
    "                * float(self.hparam.num_train_epochs)\n",
    "            )\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                self.opt,\n",
    "                num_warmup_steps=self.hparam.warmup_steps,\n",
    "                num_training_steps=t_total,\n",
    "            )\n",
    "            self.lr_scheduler = scheduler\n",
    "            return dataloader\n",
    "\n",
    "        def val_dataloader(self):\n",
    "            val_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"validation\", args=self.hparam)\n",
    "            dataloader = DataLoader(val_dataset, batch_size=self.hparam.eval_batch_size, num_workers=1)\n",
    "            return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jF4ltkgOUZ5V"
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class LoggingCallback(pl.Callback):\n",
    "    def on_validation_end(self, trainer, pl_module):\n",
    "        logger.info(\"***** Validation results *****\")\n",
    "        if pl_module.is_logger():\n",
    "            metrics = trainer.callback_metrics\n",
    "            # Log results\n",
    "            for key in sorted(metrics):\n",
    "                if key not in [\"log\", \"progress_bar\"]:\n",
    "                    logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "\n",
    "    def on_test_end(self, trainer, pl_module):\n",
    "        logger.info(\"***** Test results *****\")\n",
    "\n",
    "        if pl_module.is_logger():\n",
    "            metrics = trainer.callback_metrics\n",
    "\n",
    "            # Log and save results to file\n",
    "            output_test_results_file = os.path.join(\n",
    "                pl_module.hparams.output_dir, \"test_results.txt\")\n",
    "            with open(output_test_results_file, \"w\") as writer:\n",
    "                for key in sorted(metrics):\n",
    "                    if key not in [\"log\", \"progress_bar\"]:\n",
    "                        logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "                        writer.write(\"{} = {}\\n\".format(\n",
    "                            key, str(metrics[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Uavt_4FBUZ5W"
   },
   "outputs": [],
   "source": [
    "args_dict = dict(\n",
    "        data_dir=\"jnlpba\",\n",
    "        output_dir=\"checkpoints\",\n",
    "        model_name_or_path=\"t5-small\",\n",
    "        tokenizer_name_or_path=\"t5-small\",\n",
    "        max_seq_length=256, \n",
    "        learning_rate=3e-4,\n",
    "        weight_decay=0.0,\n",
    "        adam_epsilon=1e-8,\n",
    "        warmup_steps=0,\n",
    "        train_batch_size=8,  \n",
    "        eval_batch_size=8,\n",
    "        num_train_epochs=1,\n",
    "        gradient_accumulation_steps=16,\n",
    "        #n_gpu=1,\n",
    "        early_stop_callback=False,\n",
    "        fp_16=True,  \n",
    "        opt_level=\"O1\", \n",
    "        max_grad_norm=1,\n",
    "        seed=42,\n",
    "        val_check_interval=0.33,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1QZz2zbUZ5X"
   },
   "source": [
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194,
     "referenced_widgets": [
      "1457da6faadc4060945edbe2473c0fa5",
      "3a5246d3b0294d67afabbea1c0e8a67a",
      "2327313a40824f5f9742c0267d7c6994",
      "c63d0d6f27ec48bfbb62f4e4399594af",
      "6d993ce16b784b47b8d15c78cba76eb6",
      "585288a196a04129a2e08c5898bbc425",
      "c87058a8047f41989c0bdb999a00bacd",
      "acf3c5b28548443ea0d192fb6709f83a",
      "ebff240b76e74853b024a64434eba36f",
      "06099d5311874f9eb9a4059a894df8d0",
      "72b7da6473d745df8977b0ce03929536"
     ]
    },
    "id": "ewHzLDJcUZ5X",
    "outputId": "50cac694-a012-4432-826c-678fffc25578"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "from datasets import DatasetDict, Dataset\n",
    "import random\n",
    "import pandas as pd\n",
    "random.seed(42)\n",
    "\n",
    "class JnlpbDataset(Dataset):\n",
    "    def __init__(self, tokenizer, dataset, type_path, portion, max_len=256):\n",
    "        self.dataset = dataset[type_path]\n",
    "        self.portion = portion\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokenizer.max_length = max_len\n",
    "        self.tokenizer.model_max_length = max_len\n",
    "        self.inputs = []\n",
    "        self.targets = []\n",
    "        self.remove()\n",
    "        self.merge()\n",
    "        self.convert()\n",
    "        self.apply()\n",
    "        self._build()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        source_ids = self.inputs[index][\"input_ids\"].squeeze()\n",
    "        target_ids = self.targets[index][\"input_ids\"].squeeze()\n",
    "        #tokens = self.tokens[index][\"tokens\"].squeeze()\n",
    "        \n",
    "        src_mask = self.inputs[index][\n",
    "            \"attention_mask\"\n",
    "        ].squeeze()  # might need to squeeze\n",
    "        target_mask = self.targets[index][\n",
    "            \"attention_mask\"\n",
    "        ].squeeze()  # might need to squeeze\n",
    "        tokens = self.dataset[\"tokens\"]\n",
    "        \n",
    "        return {\n",
    "            \"source_ids\": source_ids,\n",
    "            \"source_mask\": src_mask,\n",
    "            \"target_ids\": target_ids,\n",
    "            \"target_mask\": target_mask,\n",
    "            \"tokens\": tokens,\n",
    "        }\n",
    "    \n",
    "    def remove(self):\n",
    "        df = pd.DataFrame(self.dataset)\n",
    "        df = df[df[\"tokens\"].apply(lambda x: \";\" not in x)]\n",
    "        self.dataset = df\n",
    "\n",
    "    def map_tags(self, row):\n",
    "        mapping = {\n",
    "            0: \"O\",\n",
    "            1: \"B-DNA\",\n",
    "            2: \"I-DNA\",\n",
    "            3: \"B-RNA\",\n",
    "            4: \"I-RNA\",\n",
    "            5: \"B-cell_line\",\n",
    "            6: \"I-cell_line\",\n",
    "            7: \"B-cell_type\",\n",
    "            8: \"I-cell_type\",\n",
    "            9: \"B-protein\",\n",
    "            10: \"I-protein\",\n",
    "        }\n",
    "        row[\"ner_tags\"] = [[mapping[tag] for tag in row[\"ner_tags\"]]][0]\n",
    "        return row\n",
    "\n",
    "    def convert(self):\n",
    "        df_train = pd.DataFrame(self.dataset)\n",
    "        l = []\n",
    "        l_temp = []\n",
    "        for i in range(len(df_train)):\n",
    "            for j in range(len(df_train[\"ner_tags\"][i])):\n",
    "                if df_train[\"ner_tags\"][i][j] != \"O\":\n",
    "                    l_temp.append(\n",
    "                        df_train[\"ner_tags\"][i][j] + \": \" + df_train[\"tokens\"][i][j]\n",
    "                    )\n",
    "            l.append(l_temp)\n",
    "            l_temp = []\n",
    "        d = {\"spans\": l}\n",
    "        df_train = df_train.assign(spans=l)\n",
    "        train = Dataset.from_pandas(df_train)\n",
    "        self.dataset = train\n",
    "        return train\n",
    "\n",
    "    def merge_tags(self, tags, tokens):\n",
    "        merged_tags = []\n",
    "        merged_tokens = []\n",
    "        i = 0\n",
    "        while i < len(tags):\n",
    "            if tags[i].startswith(\"B-\"):\n",
    "                merged_tag = tags[i][2:]\n",
    "                merged_token = tokens[i]\n",
    "                i += 1\n",
    "                while i < len(tags) and tags[i].startswith(\"I-\"):\n",
    "                    merged_tag += \" \" + tags[i][2:]\n",
    "                    merged_token += \" \" + tokens[i]\n",
    "                    i += 1\n",
    "                merged_tags.append(merged_tag)\n",
    "                merged_tokens.append(merged_token)\n",
    "            else:\n",
    "                merged_tags.append(tags[i])\n",
    "                merged_tokens.append(tokens[i])\n",
    "                i += 1\n",
    "        for i in range(len(merged_tags)):\n",
    "            s = merged_tags[i].split()[0]\n",
    "            s = s[0].upper() + s[1:]\n",
    "            merged_tags[i] = s\n",
    "        return merged_tags, merged_tokens\n",
    "\n",
    "    def merge(self):\n",
    "        df_train = pd.DataFrame(self.dataset)\n",
    "        df_train = df_train.apply(self.map_tags, axis=1)\n",
    "        df_train[[\"ner_tags\", \"tokens\"]] = df_train.apply(\n",
    "            lambda x: self.merge_tags(x[\"ner_tags\"], x[\"tokens\"]),\n",
    "            axis=1,\n",
    "            result_type=\"expand\",\n",
    "        )\n",
    "        self.dataset = Dataset.from_pandas(df_train)\n",
    "\n",
    "    def _build(self):\n",
    "        for idx in range(len(self.dataset)):\n",
    "            input_, target = \" \".join(self.dataset[idx][\"tokens\"]), \"; \".join(\n",
    "                self.dataset[idx][\"spans\"]\n",
    "            )\n",
    "            #tokens = self.dataset[idx][\"tokens\"] + [\"</s>\"]\n",
    "            input_ = input_.lower() + \" </s>\"\n",
    "            target = target.lower() + \" </s>\"\n",
    "            tokenized_inputs = self.tokenizer.batch_encode_plus(\n",
    "                [input_],\n",
    "                max_length=self.max_len,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            tokenized_targets = self.tokenizer.batch_encode_plus(\n",
    "                [target],\n",
    "                max_length=self.max_len,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "            )    \n",
    "            self.inputs.append(tokenized_inputs)\n",
    "            self.targets.append(tokenized_targets)\n",
    "\n",
    "    def missing(self, row):\n",
    "        lst = row[\"ner_tags\"]\n",
    "        if any(x != 0 for x in lst):\n",
    "            index = random.choice([i for i, x in enumerate(lst) if x != 0])\n",
    "            lst[index] = 0\n",
    "            row[\"ner_tags\"] = lst\n",
    "            return row\n",
    "        else:\n",
    "            return row\n",
    "\n",
    "    def wrong(self, row, num_tags):\n",
    "        lst = row[\"ner_tags\"]\n",
    "        tags = []\n",
    "        for i in range(1, num_tags):\n",
    "            tags.append(i)\n",
    "        if any(x != 0 for x in lst):\n",
    "            indices = [i for i, x in enumerate(lst) if x != 0]\n",
    "            random_index = random.choice(indices)\n",
    "            current_value = lst[random_index]\n",
    "            random_number = random.choice(\n",
    "                [x for x in [1, 2, 3, 4, 5] if x != current_value]\n",
    "            )\n",
    "            lst[random_index] = random_number\n",
    "            row[\"ner_tags\"] = lst\n",
    "            return row\n",
    "        else:\n",
    "            return row\n",
    "\n",
    "    def uncomplete(self):\n",
    "        pass\n",
    "\n",
    "    def apply(self):\n",
    "        num_portion = int(len(self.dataset) * self.portion / 100)\n",
    "        df = self.dataset.to_pandas()\n",
    "        tags = [tag for row in df[\"ner_tags\"] for tag in row]\n",
    "        unique_tags = set(tags)\n",
    "        mapping = {\n",
    "            \"O\": 0,\n",
    "            \"RNA\": 1,\n",
    "            \"DNA\": 2,\n",
    "            \"Cell_line\": 3,\n",
    "            \"Cell_type\": 4,\n",
    "            \"Protein\": 5,\n",
    "        }\n",
    "        df[\"ner_tags\"] = [[mapping[tag] for tag in tags] for tags in df[\"ner_tags\"]]\n",
    "        for i in range(num_portion):\n",
    "            random_number = random.randint(1, 2)\n",
    "            if random_number == 1:\n",
    "                new_row = self.missing(df.iloc[i])\n",
    "                df.iloc[i] = new_row\n",
    "            elif random_number == 2:\n",
    "                num_tags = len(unique_tags)\n",
    "                new_row = self.wrong(df.iloc[i], num_tags)\n",
    "                df.iloc[i] = new_row\n",
    "        self.dataset = Dataset.from_pandas(df)\n",
    "\n",
    "    def get_dataset(self):\n",
    "        return self.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxhager/.virtualenvs/thesis/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Qr2IJMrIUZ5Y"
   },
   "outputs": [],
   "source": [
    "args = argparse.Namespace(**args_dict)\n",
    "model = T5FineTuner(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "dVIV1HbOUZ5Z"
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"max\",\n",
    "        save_on_train_epoch_end=True\n",
    "    )\n",
    "\n",
    "train_params = dict(\n",
    "        accumulate_grad_batches=args.gradient_accumulation_steps,\n",
    "        accelerator='cpu',\n",
    "        #gpus=args.n_gpu,\n",
    "        max_epochs=args.num_train_epochs,\n",
    "        # early_stop_callback=False,\n",
    "        precision=32,\n",
    "        # amp_level=args.opt_level,\n",
    "        gradient_clip_val=args.max_grad_norm,\n",
    "        # checkpoint_callback=checkpoint_callback,\n",
    "        # logger=wandb_logger,\n",
    "        callbacks=[checkpoint_callback, LoggingCallback()],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6B2SgQ3VUZ5Z"
   },
   "outputs": [],
   "source": [
    "def get_dataset(tokenizer, type_path, args):\n",
    "        tokenizer.max_length = args.max_seq_length\n",
    "        tokenizer.model_max_length = args.max_seq_length\n",
    "        jnlpba = load_dataset(\"jnlpba\", split=[\"train[:1]\", \"validation[:1]\"])\n",
    "        jnlpba = DatasetDict({\"train\": jnlpba[0], \"validation\": jnlpba[1]})\n",
    "        dataset = jnlpba\n",
    "        return JnlpbDataset(\n",
    "            tokenizer=tokenizer, dataset=dataset, type_path=type_path, portion=0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5FineTuner.load_from_checkpoint(\"weights/Stark_T5.ckpt\")\n",
    "#lightning_logs/version_0/checkpoints/\n",
    "#model.load_state_dict(torch.load(\"lightning_logs/version_0/checkpoints/epoch=0-step=142.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_true(incoming, actual):\n",
    "    l_targets = [\n",
    "        [tuple_list[0] for tuple_list in sublist] for sublist in actual\n",
    "    ]\n",
    "    l_predictions = []\n",
    "    for x in incoming:\n",
    "        result = re.split(\";(?![^\\(]*\\))\", x)\n",
    "        result = [x.strip() for x in result]\n",
    "        l_predictions.append([{e.split(\":\")[0].strip(): e.split(\":\")[1].strip()} for e in result if e])\n",
    "    result = []\n",
    "    for inner_list in l_targets:\n",
    "        outcome_inner = []\n",
    "        for word in inner_list:\n",
    "            found = False\n",
    "            for dict_list in l_predictions:\n",
    "                for dict_item in dict_list:\n",
    "                    if word.lower() in dict_item.values():\n",
    "                        outcome_inner.append(list(dict_item.keys())[0])\n",
    "                        found = True\n",
    "                        break\n",
    "                if found:\n",
    "                    break\n",
    "            if not found:\n",
    "                outcome_inner.append(\"O\")\n",
    "        result.append(outcome_inner)\n",
    "    return result\n",
    "\n",
    "def label_pred(incoming, actual):\n",
    "    l_targets = [\n",
    "        [tuple_list[0] for tuple_list in sublist] for sublist in actual\n",
    "    ]\n",
    "    l_predictions = []\n",
    "    for string in incoming:\n",
    "        matches = [\n",
    "            match\n",
    "            for match in re.findall(\n",
    "                r\"(rna: (.+?))(;|$)|(dna: (.+?))(;|$)|(cell_line: (.+?))(;|$)|(protein: (.+?))(;|$)|(cell_type: (.+?))(;|$)\",\n",
    "                string,\n",
    "            )\n",
    "            if match[1] or match[4] or match[7] or match[10] or match[13]\n",
    "        ]\n",
    "        inner_list = []\n",
    "        for match in matches:\n",
    "            if match[1]:\n",
    "                inner_list.append({\"rna\": match[1]})\n",
    "            if match[4]:\n",
    "                inner_list.append({\"dna\": match[4]})\n",
    "            if match[7]:\n",
    "                inner_list.append({\"cell_line\": match[7]})\n",
    "            if match[10]:\n",
    "                inner_list.append({\"protein\": match[10]})\n",
    "            if match[13]:\n",
    "                inner_list.append({\"cell_type\": match[13]})\n",
    "        l_predictions.append(inner_list)\n",
    "\n",
    "    result = []\n",
    "    for inner_list in l_targets:\n",
    "        outcome_inner = []\n",
    "        for word in inner_list:\n",
    "            found = False\n",
    "            for dict_list in l_predictions:\n",
    "                for dict_item in dict_list:\n",
    "                    if word.lower() in dict_item.values():\n",
    "                        outcome_inner.append(list(dict_item.keys())[0])\n",
    "                        found = True\n",
    "                        break\n",
    "                if found:\n",
    "                    break\n",
    "            if not found:\n",
    "                outcome_inner.append(\"O\")\n",
    "        result.append(outcome_inner)\n",
    "    return result\n",
    "\n",
    "def val_preprocessing(true, pred):\n",
    "    new_true = []\n",
    "    new_pred = []\n",
    "    for i in range(len(true)):\n",
    "        if true[i] == 0 and pred[i] == 0:\n",
    "            continue\n",
    "        else:\n",
    "            new_true.append(true[i])\n",
    "            new_pred.append(pred[i])\n",
    "    return new_true, new_pred\n",
    "    \n",
    "def map_tags(lst):\n",
    "    mapping = {\n",
    "        \"O\": 0,\n",
    "        \"rna\": 1,\n",
    "        \"dna\": 2,\n",
    "        \"cell_line\": 3,\n",
    "        \"cell_type\": 4,\n",
    "        \"protein\": 5,\n",
    "    }\n",
    "    result = [[mapping[tag] for tag in tags] for tags in lst]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset jnlpba (/Users/maxhager/.cache/huggingface/datasets/jnlpba/jnlpba/1.0.0/3062f220823930cffde7976b694aa67bac3b06c322a02ced92d3761519810ce4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9528401a2a4d3e842c1f7be4bdc002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-----------------\n",
      "2-----------------\n",
      "3-----------------\n",
      "4-----------------\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'JnlpbDataset' on <module '__main__' (built-in)>\n",
      "wandb: Network error (ConnectTimeout), entering retry loop.\n",
      "wandb: Network error (ConnectionError), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "jnlpba = load_dataset(\"jnlpba\", split=[\"train[:1]\", \"validation[:1]\"])\n",
    "jnlpba = DatasetDict({\"train\": jnlpba[0], \"validation\": jnlpba[1]})\n",
    "test_dataset = JnlpbDataset(tokenizer=tokenizer, dataset=jnlpba, type_path='validation', portion=0)\n",
    "print(\"1-----------------\")\n",
    "#todo check if my removing shuffle=True of has any dramatic impact \n",
    "test_loader = DataLoader(test_dataset, batch_size=32,\n",
    "                             num_workers=2)\n",
    "print(\"2-----------------\")\n",
    "model.model.eval()\n",
    "print(\"3-----------------\")\n",
    "model = model.to(\"cpu\")\n",
    "print(\"4-----------------\")\n",
    "outputs = []\n",
    "targets = []\n",
    "all_text = []\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "predictions = []\n",
    "predictions_temp = []\n",
    "counter = 0\n",
    "print(len(test_loader))\n",
    "for batch in tqdm(test_loader):\n",
    "    print(\"5-----------------\")\n",
    "    counter += 1\n",
    "    input_ids = batch['source_ids'].to(\"cpu\")\n",
    "    attention_mask = batch['source_mask'].to(\"cpu\")\n",
    "    outs = model.model.generate(input_ids=input_ids,\n",
    "                                attention_mask=attention_mask)\n",
    "\n",
    "    dec = [tokenizer.decode(ids, skip_special_tokens=True,\n",
    "                            clean_up_tokenization_spaces=False).strip() for ids in outs]\n",
    "\n",
    "    target = [tokenizer.decode(ids, skip_special_tokens=True,  clean_up_tokenization_spaces=False).strip()\n",
    "                for ids in batch[\"target_ids\"]]\n",
    "    texts = [tokenizer.decode(ids, skip_special_tokens=True,  clean_up_tokenization_spaces=False).strip()\n",
    "                for ids in batch[\"source_ids\"]]\n",
    "    #print(\"outs\")\n",
    "    #print(outs)\n",
    "    #print(30*\"-\")\n",
    "    print(\"dec\")\n",
    "    print(dec)\n",
    "    print(30*\"-\")\n",
    "    print(\"target\")\n",
    "    print(target)\n",
    "    print(30*\"-\")\n",
    "    print(\"texts\")\n",
    "    print(texts)\n",
    "    print(30*\"-\")\n",
    "    \n",
    "    #print(target)\n",
    "    '''predicted_label = label_pred(dec, batch[\"tokens\"])\n",
    "    true_label = label_true(target, batch[\"tokens\"])\n",
    "\n",
    "    outputs.extend(dec)\n",
    "    targets.extend(target)\n",
    "    true_labels.extend(true_label)\n",
    "    pred_labels.extend(predicted_label)\n",
    "    all_text.extend(texts)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wandb.log(\\n    {\\n        \"precision\": precision,\\n        \"recall\": recall,\\n        \"f1\": fscore,\\n        \"accuracy\": accuracy,\\n    }\\n)'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''print(\"batch ids\")\n",
    "    print(batch_idx)\n",
    "    print(30*\"-\")\n",
    "    outputs = []\n",
    "    targets = []\n",
    "    all_text = []\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    predictions = []\n",
    "    predictions_temp = []\n",
    "    l_true_labels = []\n",
    "    l_pred_labels = []\n",
    "    input_ids = batch[\"source_ids\"].to(\"cuda\")\n",
    "    attention_mask = batch[\"source_mask\"].to(\"cuda\")\n",
    "    outs = model.model.generate(\n",
    "        input_ids=input_ids, attention_mask=attention_mask\n",
    "    )\n",
    "    dec = [\n",
    "        tokenizer.decode(\n",
    "            ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "        ).strip()\n",
    "        for ids in outs\n",
    "    ]\n",
    "    print(\"dec\")\n",
    "    print(dec)\n",
    "    print(30*\"-\")\n",
    "    target = [\n",
    "        tokenizer.decode(\n",
    "            ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "        ).strip()\n",
    "        for ids in batch[\"target_ids\"]\n",
    "    ]\n",
    "    print(\"target\")\n",
    "    print(target)\n",
    "    print(30*\"-\")\n",
    "    texts = [\n",
    "        tokenizer.decode(\n",
    "            ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "        ).strip()\n",
    "        for ids in batch[\"source_ids\"]\n",
    "    ]\n",
    "    print(\"text not stripped\")\n",
    "    text = [\n",
    "        tokenizer.decode(\n",
    "            ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "        ).strip()\n",
    "        for ids in batch[\"source_ids\"]\n",
    "    ]\n",
    "    print(text)\n",
    "    print(30*\"-\")\n",
    "    print(\"text\")\n",
    "    print(texts)\n",
    "    print(30*\"-\")\n",
    "    print(\"token length\")\n",
    "    print(len(batch[\"tokens\"]))\n",
    "    len_source_ids = len(batch[\"source_ids\"])\n",
    "    print(\"tokens length\")\n",
    "    print(len(batch[\"tokens\"][self.batch_counter: self.batch_counter + len_source_ids]))\n",
    "    print(\"source ids length\")\n",
    "    print(len(batch[\"source_ids\"]))\n",
    "    print(\"target_ids length\")\n",
    "    print(len(batch[\"target_ids\"]))\n",
    "    print(\"self batch counter\")\n",
    "    print(self.batch_counter)\n",
    "    print(\"self batch counter + len source ids\")\n",
    "    print(self.batch_counter + len_source_ids)\n",
    "    print(30*\"-\")\n",
    "    true_label = self.label_true(target, batch[\"tokens\"][self.batch_counter: self.batch_counter + len_source_ids])\n",
    "    predicted_label = self.label_pred(dec, batch[\"tokens\"][self.batch_counter: self.batch_counter + len_source_ids])\n",
    "    self.batch_counter += len_source_ids\n",
    "    #self.counter += self.hparam.eval_batch_size''' \n",
    "pred_mapped = map_tags(pred_labels)\n",
    "true_mapped = map_tags(true_labels)\n",
    "#self.true.extend(np.array(true_mapped).flatten())\n",
    "#self.pred.extend(np.array(pred_mapped).flatten())\n",
    "true_label = np.concatenate(true_mapped)\n",
    "predicted_label = np.concatenate(pred_mapped)\n",
    "true_label, predicted_label = val_preprocessing(true_label, predicted_label)\n",
    "cm = confusion_matrix(true_label, predicted_label)\n",
    "cm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "plt.imshow(cm, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.colorbar()\n",
    "mapping = {\n",
    "    \"O\": 0,\n",
    "    \"rna\": 1,\n",
    "    \"dna\": 2,\n",
    "    \"cell_l\": 3,\n",
    "    \"cell_t\": 4,\n",
    "    \"protein\": 5,\n",
    "}\n",
    "reverse_mapping = {v: k for k, v in mapping.items()}\n",
    "ax = plt.gca()\n",
    "ax.set_xticks([i for i in range(len(mapping))])\n",
    "ax.set_yticks([i for i in range(len(mapping))])\n",
    "ax.set_xticklabels([reverse_mapping[i] for i in range(len(mapping))])\n",
    "ax.set_yticklabels([reverse_mapping[i] for i in range(len(mapping))])\n",
    "wandb.log({\"confusion_matrix\": wandb.Image(plt)})\n",
    "plt.clf()\n",
    "accuracy = accuracy_score(true_label, predicted_label)\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(\n",
    "    true_label, predicted_label, zero_division=1, average=\"weighted\"\n",
    ")\n",
    "'''wandb.log(\n",
    "    {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": fscore,\n",
    "        \"accuracy\": accuracy,\n",
    "    }\n",
    ")'''  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28503049541677067 0.3088061138557229 0.28503049541677067 0.29080033255404575\n"
     ]
    }
   ],
   "source": [
    "#accuracy = accuracy_score(true_label[:40], predicted_label[:40])\n",
    "print(accuracy, precision, recall, fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'api = wandb.Api()\\nrun = api.run(\"maxhager28/Bachelor_Thesis/a04j9ypt\")\\nbest_model = wandb.restore(\\'lightning_logs/version_0/checkpoints/epoch=0-step=142.ckpt\\', run_path=\"maxhager28/Bachelor_Thesis/a04j9ypt\")\\nfor file in run.files():\\n\\n    if file == \"lightning_logs/version_0/checkpoints/epoch=0-step=142.ckpt\":\\n        file.download(replace=True)\\n        \\n    print(file)'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''api = wandb.Api()\n",
    "run = api.run(\"maxhager28/Bachelor_Thesis/a04j9ypt\")\n",
    "best_model = wandb.restore('lightning_logs/version_0/checkpoints/epoch=0-step=142.ckpt', run_path=\"maxhager28/Bachelor_Thesis/a04j9ypt\")\n",
    "for file in run.files():\n",
    "\n",
    "    if file == \"lightning_logs/version_0/checkpoints/epoch=0-step=142.ckpt\":\n",
    "        file.download(replace=True)\n",
    "        \n",
    "    print(file)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WoAI_CIHUZ5Z",
    "outputId": "3d6a6b76-eec4-4a46-f696-5777b6876e0f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:468: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n",
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/lightning_fabric/accelerators/tpu.py\", line 79, in _inner_f\n",
      "    queue.put(func(*args, **kwargs))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/lightning_fabric/accelerators/tpu.py\", line 117, in _is_device_tpu\n",
      "    return (xm.xrt_world_size() > 1) or bool(xm.get_xla_supported_devices(\"TPU\"))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch_xla/core/xla_model.py\", line 137, in get_xla_supported_devices\n",
      "    xla_devices = _DEVICES.value\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch_xla/utils/utils.py\", line 32, in value\n",
      "    self._value = self._gen_fn()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch_xla/core/xla_model.py\", line 19, in <lambda>\n",
      "    _DEVICES = xu.LazyProperty(lambda: torch_xla._XLAC._xla_get_devices())\n",
      "RuntimeError: tensorflow/compiler/xla/xla_client/computation_client.cc:280 : Missing XLA configuration\n",
      "TPU available: None, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "662faa125adb4dd68f09f93eac80788d",
      "b7a2f15c16c94d2086db286ac239fcb9",
      "0899dc0a540a430c814136af7fe38fdc",
      "380c307d9ac847ff9f3f0db294d5910d",
      "6d61db62adce43f2ab937c6158d43fc2",
      "f6d6c3f03fac4ea9a0329b77850f636d",
      "1ccb9088b26b4a248bfd6b74c6caeeba",
      "5a8a585a806143e7a7ef301ee1f382d2",
      "b4f4dd7c1f7c498e85d5e64f092e2e72",
      "bceadc9a60d542519b7dbfeefe07ac2b",
      "de9dc0616da44bf7bac717c5638e0b6b",
      "6e44214be737402fa52392042e82a7f3",
      "4e12733c334748bb82fb181f802150db",
      "f83f2097f87a49d598c978c3df1fb286",
      "432948c7c18849c0b378feb6eafb1686",
      "e91b24c9cec5496d99d7b2619aaafeeb",
      "ba3fed06366448b3aadd48269292bc30",
      "abd3f96da1b74ecdbecbdc15cf821cba",
      "9dd4bc773c1c462bb4d35b072b502cef",
      "acd82e71563049108828a95ef1ec7f0d",
      "e82e13634889401a9cfe98390f7642ef",
      "f4ff2b448c904d3698ac64e63a963b20",
      "4023ea4693b1487b85d593d504ab2115",
      "ed82afece02b480591b666f0f163b0fb",
      "942e54b7236b40dc962b041b06600b27",
      "a155b49031094da8a077f5ed983f2530",
      "33531ef26ba8420998df9ce3f26c2f9e",
      "4fcf8a71e545436aa6e8475a6eebae6f",
      "3cde97f8958d4ddd9d991102ded17d8f",
      "4e279cb2938c425a883a37493654599b",
      "e2fb5cb3e3914ab791e7a655c66eb74e",
      "fdbadc100cd1467bbec848143a8edaf9",
      "59f76773b6c246c3a31abb2ab730fe6d",
      "6b20d21363cf42ffa948efa24ee83060",
      "1742f5156bb3448d89c89f3adbd95c74",
      "bd310192478f48b29934eb5aee031c2b",
      "b1c810d6d2dd4eff81f8c321d2a01d30",
      "9cc5dd1d8534474c9d5b7c3cdcc520a4",
      "68679c831522415d98d08cea01991f32",
      "a7eb49af44664a218b6ee3ece2e9e387",
      "47b59f4150f84b088e34278d3751c5c0",
      "59f3574afadd44a48197c217ee8360dc",
      "23c16f5a77534a73af8a03eeeccedb2f",
      "16da797ba7034d76bca81735ccc85098",
      "558a4a0336504ed6ba62aaca320f467c",
      "01da20ff2ff44541bb045c3b8e11e3a5",
      "9c10bf7a956347a2a7bf4100dff8461b",
      "ad76868fb7304201bb400e6fd2fd1eb7",
      "2cc8b33e4f944b5bae4755da02f72491",
      "c27d5f2e87a6423fb67d2d7c368a4c12",
      "5fd6f11620664c858884b15d27453b69",
      "0ae638299265467a80466acf83e96ec5",
      "f99df0d8af5b4e66b4b9eb339bc64538",
      "b6ec6fa86a4340daabfa70ff18d6e625",
      "265288640e014b1bac7b17c75a74121b",
      "9569f1087d004e38ab733daa2f61484d",
      "6f502b7867c540769a8e4bf906cbe0e9",
      "52d3e7b0b40a4cfaba1bb1b80c5a8890",
      "126613fa302f40d0a35b1dd0d897d206",
      "54779d1826e34dfeb4909680f7fdc8f6",
      "7e0a8c44e9a1481baa7c92ade88e0e91",
      "71dd27b9277d4d89a8b25fafee20737e",
      "aff23145e91f4aa7aeded65871b1b884",
      "f64aa760680d427abded36d655dad9c7",
      "3592864eb55943f4906f22ff4b3d33cc",
      "921298f74974403faf29b416e178f8bb",
      "ed7203669f774d49b9101b125f300866",
      "c395745bab014978bd48381fbacb2b8e",
      "53d0229416c848838497fcb75d98da60",
      "f8f25779e5274cf6a89cf8de576c464c",
      "1c121889deca40c38a8732d4a9d6a8a3",
      "73e06c716b8844c1a0f0e8f04e98578c",
      "cf3bfefeaa0e4530ac0f438f38b8f357",
      "43724cde8c1f4888969d6fc634c1adaa",
      "1a80c832bf3d4403902d0520c4a5a6d5",
      "aea79cd070444751bf140a29d82ec95f",
      "ef8150ea5dfd4d29adba6326624ee539"
     ]
    },
    "id": "flAVWfevUZ5Z",
    "outputId": "602ad324-e47e-4119-c54f-f9d7d9019e92"
   },
   "outputs": [],
   "source": [
    "#trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb.save('lightning_logs/version_0/checkpoints/*ckpt*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wandb.alert(\\n    title=\"End of training.\", \\n    text=\"Training finished successfully.\",\\n)'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''wandb.alert(\n",
    "    title=\"End of training.\", \n",
    "    text=\"Training finished successfully.\",\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Seq2seq_jnlpba_weak_100_cm</strong> at: <a href=\"https://wandb.ai/maxhager28/Bachelor_Thesis/runs/l5jay8ym\" target=\"_blank\">https://wandb.ai/maxhager28/Bachelor_Thesis/runs/l5jay8ym</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230212_084615-l5jay8ym/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m103"
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "f68a4539c9a11cef9bf0819cdddedfa00ec9d5fcff3291c5b30fad122c003099"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01da20ff2ff44541bb045c3b8e11e3a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c27d5f2e87a6423fb67d2d7c368a4c12",
      "placeholder": "​",
      "style": "IPY_MODEL_5fd6f11620664c858884b15d27453b69",
      "value": "Validation DataLoader 0: 100%"
     }
    },
    "06099d5311874f9eb9a4059a894df8d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0899dc0a540a430c814136af7fe38fdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a8a585a806143e7a7ef301ee1f382d2",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b4f4dd7c1f7c498e85d5e64f092e2e72",
      "value": 2
     }
    },
    "0ae638299265467a80466acf83e96ec5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "126613fa302f40d0a35b1dd0d897d206": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3592864eb55943f4906f22ff4b3d33cc",
      "placeholder": "​",
      "style": "IPY_MODEL_921298f74974403faf29b416e178f8bb",
      "value": " 13/13 [00:07&lt;00:00,  1.68it/s]"
     }
    },
    "1457da6faadc4060945edbe2473c0fa5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3a5246d3b0294d67afabbea1c0e8a67a",
       "IPY_MODEL_2327313a40824f5f9742c0267d7c6994",
       "IPY_MODEL_c63d0d6f27ec48bfbb62f4e4399594af"
      ],
      "layout": "IPY_MODEL_6d993ce16b784b47b8d15c78cba76eb6"
     }
    },
    "16da797ba7034d76bca81735ccc85098": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1742f5156bb3448d89c89f3adbd95c74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_68679c831522415d98d08cea01991f32",
      "placeholder": "​",
      "style": "IPY_MODEL_a7eb49af44664a218b6ee3ece2e9e387",
      "value": "Epoch 2: 100%"
     }
    },
    "1a80c832bf3d4403902d0520c4a5a6d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1c121889deca40c38a8732d4a9d6a8a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": "100%"
     }
    },
    "1ccb9088b26b4a248bfd6b74c6caeeba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2327313a40824f5f9742c0267d7c6994": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_acf3c5b28548443ea0d192fb6709f83a",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ebff240b76e74853b024a64434eba36f",
      "value": 2
     }
    },
    "23c16f5a77534a73af8a03eeeccedb2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "265288640e014b1bac7b17c75a74121b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2cc8b33e4f944b5bae4755da02f72491": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": "100%"
     }
    },
    "33531ef26ba8420998df9ce3f26c2f9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3592864eb55943f4906f22ff4b3d33cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "380c307d9ac847ff9f3f0db294d5910d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bceadc9a60d542519b7dbfeefe07ac2b",
      "placeholder": "​",
      "style": "IPY_MODEL_de9dc0616da44bf7bac717c5638e0b6b",
      "value": " 2/2 [00:01&lt;00:00,  1.65it/s]"
     }
    },
    "3a5246d3b0294d67afabbea1c0e8a67a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_585288a196a04129a2e08c5898bbc425",
      "placeholder": "​",
      "style": "IPY_MODEL_c87058a8047f41989c0bdb999a00bacd",
      "value": "100%"
     }
    },
    "3cde97f8958d4ddd9d991102ded17d8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4023ea4693b1487b85d593d504ab2115": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ed82afece02b480591b666f0f163b0fb",
       "IPY_MODEL_942e54b7236b40dc962b041b06600b27",
       "IPY_MODEL_a155b49031094da8a077f5ed983f2530"
      ],
      "layout": "IPY_MODEL_33531ef26ba8420998df9ce3f26c2f9e"
     }
    },
    "432948c7c18849c0b378feb6eafb1686": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e82e13634889401a9cfe98390f7642ef",
      "placeholder": "​",
      "style": "IPY_MODEL_f4ff2b448c904d3698ac64e63a963b20",
      "value": " 2/2 [00:00&lt;00:00, 70.40it/s]"
     }
    },
    "43724cde8c1f4888969d6fc634c1adaa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47b59f4150f84b088e34278d3751c5c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e12733c334748bb82fb181f802150db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba3fed06366448b3aadd48269292bc30",
      "placeholder": "​",
      "style": "IPY_MODEL_abd3f96da1b74ecdbecbdc15cf821cba",
      "value": "100%"
     }
    },
    "4e279cb2938c425a883a37493654599b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fcf8a71e545436aa6e8475a6eebae6f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52d3e7b0b40a4cfaba1bb1b80c5a8890": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aff23145e91f4aa7aeded65871b1b884",
      "max": 13,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f64aa760680d427abded36d655dad9c7",
      "value": 13
     }
    },
    "53d0229416c848838497fcb75d98da60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43724cde8c1f4888969d6fc634c1adaa",
      "max": 13,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1a80c832bf3d4403902d0520c4a5a6d5",
      "value": 13
     }
    },
    "54779d1826e34dfeb4909680f7fdc8f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": "100%"
     }
    },
    "558a4a0336504ed6ba62aaca320f467c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_01da20ff2ff44541bb045c3b8e11e3a5",
       "IPY_MODEL_9c10bf7a956347a2a7bf4100dff8461b",
       "IPY_MODEL_ad76868fb7304201bb400e6fd2fd1eb7"
      ],
      "layout": "IPY_MODEL_2cc8b33e4f944b5bae4755da02f72491"
     }
    },
    "585288a196a04129a2e08c5898bbc425": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59f3574afadd44a48197c217ee8360dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "59f76773b6c246c3a31abb2ab730fe6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5a8a585a806143e7a7ef301ee1f382d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5fd6f11620664c858884b15d27453b69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "662faa125adb4dd68f09f93eac80788d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b7a2f15c16c94d2086db286ac239fcb9",
       "IPY_MODEL_0899dc0a540a430c814136af7fe38fdc",
       "IPY_MODEL_380c307d9ac847ff9f3f0db294d5910d"
      ],
      "layout": "IPY_MODEL_6d61db62adce43f2ab937c6158d43fc2"
     }
    },
    "68679c831522415d98d08cea01991f32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b20d21363cf42ffa948efa24ee83060": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1742f5156bb3448d89c89f3adbd95c74",
       "IPY_MODEL_bd310192478f48b29934eb5aee031c2b",
       "IPY_MODEL_b1c810d6d2dd4eff81f8c321d2a01d30"
      ],
      "layout": "IPY_MODEL_9cc5dd1d8534474c9d5b7c3cdcc520a4"
     }
    },
    "6d61db62adce43f2ab937c6158d43fc2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": "100%"
     }
    },
    "6d993ce16b784b47b8d15c78cba76eb6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e44214be737402fa52392042e82a7f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4e12733c334748bb82fb181f802150db",
       "IPY_MODEL_f83f2097f87a49d598c978c3df1fb286",
       "IPY_MODEL_432948c7c18849c0b378feb6eafb1686"
      ],
      "layout": "IPY_MODEL_e91b24c9cec5496d99d7b2619aaafeeb"
     }
    },
    "6f502b7867c540769a8e4bf906cbe0e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e0a8c44e9a1481baa7c92ade88e0e91",
      "placeholder": "​",
      "style": "IPY_MODEL_71dd27b9277d4d89a8b25fafee20737e",
      "value": "Validation DataLoader 0: 100%"
     }
    },
    "71dd27b9277d4d89a8b25fafee20737e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "72b7da6473d745df8977b0ce03929536": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "73e06c716b8844c1a0f0e8f04e98578c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e0a8c44e9a1481baa7c92ade88e0e91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "921298f74974403faf29b416e178f8bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "942e54b7236b40dc962b041b06600b27": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e279cb2938c425a883a37493654599b",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e2fb5cb3e3914ab791e7a655c66eb74e",
      "value": 2
     }
    },
    "9569f1087d004e38ab733daa2f61484d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6f502b7867c540769a8e4bf906cbe0e9",
       "IPY_MODEL_52d3e7b0b40a4cfaba1bb1b80c5a8890",
       "IPY_MODEL_126613fa302f40d0a35b1dd0d897d206"
      ],
      "layout": "IPY_MODEL_54779d1826e34dfeb4909680f7fdc8f6"
     }
    },
    "9c10bf7a956347a2a7bf4100dff8461b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ae638299265467a80466acf83e96ec5",
      "max": 13,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f99df0d8af5b4e66b4b9eb339bc64538",
      "value": 13
     }
    },
    "9cc5dd1d8534474c9d5b7c3cdcc520a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "9dd4bc773c1c462bb4d35b072b502cef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a155b49031094da8a077f5ed983f2530": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fdbadc100cd1467bbec848143a8edaf9",
      "placeholder": "​",
      "style": "IPY_MODEL_59f76773b6c246c3a31abb2ab730fe6d",
      "value": " 2/2 [00:00&lt;00:00, 72.63it/s]"
     }
    },
    "a7eb49af44664a218b6ee3ece2e9e387": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "abd3f96da1b74ecdbecbdc15cf821cba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "acd82e71563049108828a95ef1ec7f0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "acf3c5b28548443ea0d192fb6709f83a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad76868fb7304201bb400e6fd2fd1eb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6ec6fa86a4340daabfa70ff18d6e625",
      "placeholder": "​",
      "style": "IPY_MODEL_265288640e014b1bac7b17c75a74121b",
      "value": " 13/13 [00:07&lt;00:00,  1.68it/s]"
     }
    },
    "aea79cd070444751bf140a29d82ec95f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aff23145e91f4aa7aeded65871b1b884": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1c810d6d2dd4eff81f8c321d2a01d30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23c16f5a77534a73af8a03eeeccedb2f",
      "placeholder": "​",
      "style": "IPY_MODEL_16da797ba7034d76bca81735ccc85098",
      "value": " 25/25 [00:18&lt;00:00,  1.37it/s, loss=2.89, v_num=vz32, val_loss=3.090]"
     }
    },
    "b4f4dd7c1f7c498e85d5e64f092e2e72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b6ec6fa86a4340daabfa70ff18d6e625": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7a2f15c16c94d2086db286ac239fcb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6d6c3f03fac4ea9a0329b77850f636d",
      "placeholder": "​",
      "style": "IPY_MODEL_1ccb9088b26b4a248bfd6b74c6caeeba",
      "value": "Sanity Checking DataLoader 0: 100%"
     }
    },
    "ba3fed06366448b3aadd48269292bc30": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bceadc9a60d542519b7dbfeefe07ac2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd310192478f48b29934eb5aee031c2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47b59f4150f84b088e34278d3751c5c0",
      "max": 25,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_59f3574afadd44a48197c217ee8360dc",
      "value": 25
     }
    },
    "c27d5f2e87a6423fb67d2d7c368a4c12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c395745bab014978bd48381fbacb2b8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73e06c716b8844c1a0f0e8f04e98578c",
      "placeholder": "​",
      "style": "IPY_MODEL_cf3bfefeaa0e4530ac0f438f38b8f357",
      "value": "Validation DataLoader 0: 100%"
     }
    },
    "c63d0d6f27ec48bfbb62f4e4399594af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06099d5311874f9eb9a4059a894df8d0",
      "placeholder": "​",
      "style": "IPY_MODEL_72b7da6473d745df8977b0ce03929536",
      "value": " 2/2 [00:00&lt;00:00, 69.07it/s]"
     }
    },
    "c87058a8047f41989c0bdb999a00bacd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cf3bfefeaa0e4530ac0f438f38b8f357": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "de9dc0616da44bf7bac717c5638e0b6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e2fb5cb3e3914ab791e7a655c66eb74e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e82e13634889401a9cfe98390f7642ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e91b24c9cec5496d99d7b2619aaafeeb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ebff240b76e74853b024a64434eba36f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ed7203669f774d49b9101b125f300866": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c395745bab014978bd48381fbacb2b8e",
       "IPY_MODEL_53d0229416c848838497fcb75d98da60",
       "IPY_MODEL_f8f25779e5274cf6a89cf8de576c464c"
      ],
      "layout": "IPY_MODEL_1c121889deca40c38a8732d4a9d6a8a3"
     }
    },
    "ed82afece02b480591b666f0f163b0fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4fcf8a71e545436aa6e8475a6eebae6f",
      "placeholder": "​",
      "style": "IPY_MODEL_3cde97f8958d4ddd9d991102ded17d8f",
      "value": "100%"
     }
    },
    "ef8150ea5dfd4d29adba6326624ee539": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f4ff2b448c904d3698ac64e63a963b20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f64aa760680d427abded36d655dad9c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f6d6c3f03fac4ea9a0329b77850f636d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f83f2097f87a49d598c978c3df1fb286": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9dd4bc773c1c462bb4d35b072b502cef",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_acd82e71563049108828a95ef1ec7f0d",
      "value": 2
     }
    },
    "f8f25779e5274cf6a89cf8de576c464c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aea79cd070444751bf140a29d82ec95f",
      "placeholder": "​",
      "style": "IPY_MODEL_ef8150ea5dfd4d29adba6326624ee539",
      "value": " 13/13 [00:08&lt;00:00,  1.54it/s]"
     }
    },
    "f99df0d8af5b4e66b4b9eb339bc64538": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fdbadc100cd1467bbec848143a8edaf9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
