{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"SymgaR13Uh8R"},"outputs":[],"source":["!pip install transformers\n","!pip install pytorch_lightning\n","!pip install sentencepiece datasets seqeval"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"background_save":true},"id":"GocN6aLfUZ5F","outputId":"60b70702-1dea-4004-cd3e-3771026056c7"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /Users/maxhager/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import (\n","    AdamW,\n","    MT5ForConditionalGeneration,\n","    T5ForConditionalGeneration,\n","    T5Tokenizer,\n","    AutoTokenizer,\n","    get_linear_schedule_with_warmup\n",")\n","from datasets import load_dataset, load_metric\n","from datasets import DatasetDict\n","import pytorch_lightning as pl\n","from torch.utils.data import Dataset, DataLoader\n","import torch\n","import numpy as np\n","import pandas as pd\n","from nltk.tokenize import sent_tokenize\n","import argparse\n","import glob\n","import os\n","import json\n","import time\n","import logging\n","import random\n","import re\n","from itertools import chain\n","from string import punctuation\n","\n","import nltk\n","nltk.download('punkt')\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["device = torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["cpu\n"]}],"source":["print(device)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"jrjLi0gxUZ5H"},"outputs":[],"source":["def set_seed(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)\n","set_seed(42)"]},{"cell_type":"markdown","metadata":{"id":"ct0QUX4HUZ5I"},"source":["### Model\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"8pqgGWAzUZ5U"},"outputs":[],"source":["class T5FineTuner(pl.LightningModule):\n","    def __init__(self, hparam):\n","        super(T5FineTuner, self).__init__()\n","        self.hparam = hparam\n","        self.model = T5ForConditionalGeneration.from_pretrained(\n","            hparam.model_name_or_path)\n","        self.tokenizer = AutoTokenizer.from_pretrained(\n","            hparam.model_name_or_path\n","        )\n","        self.save_hyperparameters()\n","\n","    def is_logger(self):\n","        return True\n","\n","    def forward(\n","        self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, lm_labels=None\n","    ):\n","        return self.model(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            decoder_input_ids=decoder_input_ids,\n","            decoder_attention_mask=decoder_attention_mask,\n","            labels=lm_labels,\n","        )\n","\n","    def _step(self, batch):\n","        lm_labels = batch[\"target_ids\"]\n","        lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n","\n","        outputs = self(\n","            input_ids=batch[\"source_ids\"],\n","            attention_mask=batch[\"source_mask\"],\n","            lm_labels=lm_labels,\n","            decoder_attention_mask=batch['target_mask']\n","        )\n","\n","        loss = outputs[0]\n","        return loss\n","\n","    def training_step(self, batch, batch_idx):\n","        loss = self._step(batch)\n","\n","        tensorboard_logs = {\"train_loss\": loss}\n","        return {\"loss\": loss, \"log\": tensorboard_logs}\n","\n","    def training_epoch_end(self, outputs):\n","        avg_train_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n","        tensorboard_logs = {\"avg_train_loss\": avg_train_loss}\n","\n","    def validation_step(self, batch, batch_idx):\n","        #val_loss = compute_val_loss(batch)\n","        #log the val_loss metric for the ModelCheckpoint callback to monitor\n","        val_loss = self._step(batch)\n","        self.log('val_loss', val_loss, prog_bar=True)\n","        return {\"val_loss\": val_loss}\n","\n","    def validation_epoch_end(self, outputs):\n","        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n","        tensorboard_logs = {\"val_loss\": avg_loss}\n","\n","    def configure_optimizers(self):\n","        \"Prepare optimizer and schedule (linear warmup and decay)\"\n","\n","        model = self.model\n","        no_decay = [\"bias\", \"LayerNorm.weight\"]\n","        optimizer_grouped_parameters = [\n","            {\n","                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","                \"weight_decay\": self.hparam.weight_decay,\n","            },\n","            {\n","                \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n","                \"weight_decay\": 0.0,\n","            },\n","        ]\n","        optimizer = AdamW(optimizer_grouped_parameters,\n","                          lr=self.hparam.learning_rate, eps=self.hparam.adam_epsilon)\n","        self.opt = optimizer\n","        return [optimizer]\n","\n","    def optimizer_step(self,\n","                       epoch=None,\n","                       batch_idx=None,\n","                       optimizer=None,\n","                       optimizer_idx=None,\n","                       optimizer_closure=None,\n","                       on_tpu=None,\n","                       using_native_amp=None,\n","                       using_lbfgs=None\n","                       ):\n","\n","        optimizer.step(closure=optimizer_closure)\n","        optimizer.zero_grad()\n","        self.lr_scheduler.step()\n","\n","    def get_tqdm_dict(self):\n","        tqdm_dict = {\"loss\": \"{:.3f}\".format(\n","            self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n","\n","        return tqdm_dict\n","\n","    def train_dataloader(self):\n","        train_dataset = get_dataset(\n","            tokenizer=self.tokenizer, type_path=\"train\", args=self.hparam)\n","        dataloader = DataLoader(train_dataset, batch_size=self.hparam.train_batch_size,\n","                                drop_last=True, shuffle=True, num_workers=2)\n","        t_total = (\n","            (len(dataloader.dataset) //\n","             (self.hparam.train_batch_size * max(1, self.hparam.n_gpu)))\n","            // self.hparam.gradient_accumulation_steps\n","            * float(self.hparam.num_train_epochs)\n","        )\n","        scheduler = get_linear_schedule_with_warmup(\n","            self.opt, num_warmup_steps=self.hparam.warmup_steps, num_training_steps=t_total\n","        )\n","        self.lr_scheduler = scheduler\n","        return dataloader\n","\n","    def val_dataloader(self):\n","        val_dataset = get_dataset(\n","            tokenizer=self.tokenizer, type_path=\"validation\", args=self.hparam)\n","        return DataLoader(val_dataset, batch_size=self.hparam.eval_batch_size, num_workers=2)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"jF4ltkgOUZ5V"},"outputs":[],"source":["logger = logging.getLogger(__name__)\n","\n","\n","class LoggingCallback(pl.Callback):\n","    def on_validation_end(self, trainer, pl_module):\n","        logger.info(\"***** Validation results *****\")\n","        if pl_module.is_logger():\n","            metrics = trainer.callback_metrics\n","            # Log results\n","            for key in sorted(metrics):\n","                if key not in [\"log\", \"progress_bar\"]:\n","                    logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n","\n","    def on_test_end(self, trainer, pl_module):\n","        logger.info(\"***** Test results *****\")\n","\n","        if pl_module.is_logger():\n","            metrics = trainer.callback_metrics\n","\n","            # Log and save results to file\n","            output_test_results_file = os.path.join(\n","                pl_module.hparams.output_dir, \"test_results.txt\")\n","            with open(output_test_results_file, \"w\") as writer:\n","                for key in sorted(metrics):\n","                    if key not in [\"log\", \"progress_bar\"]:\n","                        logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n","                        writer.write(\"{} = {}\\n\".format(\n","                            key, str(metrics[key])))\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Uavt_4FBUZ5W"},"outputs":[],"source":["args_dict = dict(\n","    data_dir=\"jnlpba\",  # path for data files\n","    output_dir=\"checkpoints\",  # path to save the checkpoints\n","    model_name_or_path='t5-small',\n","    tokenizer_name_or_path='t5-small',\n","    max_seq_length=256,  # todo figure out\n","    learning_rate=3e-4,\n","    weight_decay=0.0,\n","    adam_epsilon=1e-8,\n","    warmup_steps=0,\n","    train_batch_size=8, # 4/2/1 if t5-small not working\n","    eval_batch_size=8,\n","    num_train_epochs=3,\n","    gradient_accumulation_steps=16,\n","    #n_gpu=1,\n","    early_stop_callback=False,\n","    fp_16=True, # if you want to enable 16-bit training then install apex and set this to true\n","    opt_level='O1', # you can find out more on optimisation levels here https://nvidia.github.io/apex/amp.html#opt-levels-and-properties\n","    max_grad_norm=1, # if you enable 16-bit training then set this to a sensible value, 0.5 is a good default\n","    seed=42,\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"D1QZz2zbUZ5X"},"source":["### Dataset\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373,"referenced_widgets":["a948414581d94776b6d4e4dc5ad95023","905065f70d2846c0b3ffd43edb9d209b","0c4a2dfb4db34a6987218d14fca65671","2f39b3b8167b408e979f99885f0a73be","cc15cd85d45b4fd89db6397133faeee8","44fc0cc48ec94431a7908b3af5e6ad9b","e14ebba3c7024183aac18b2d61c280c1","e37623fb7cbf4de5bfc4aede2aea8e68","07050080cdbe4feca8bd9f54fca26537","c06b9f7f34e94b87bc7cc5d240b11623","aabb344daf234eee9ca19075a3b56f5b"]},"executionInfo":{"elapsed":8904,"status":"ok","timestamp":1673100152584,"user":{"displayName":"Max Hager","userId":"17820186552942690415"},"user_tz":-60},"id":"ewHzLDJcUZ5X","outputId":"f5144c9a-9fe2-4f79-e2bd-755cfce76b65"},"outputs":[{"name":"stderr","output_type":"stream","text":["Found cached dataset jnlpba (/Users/maxhager/.cache/huggingface/datasets/jnlpba/jnlpba/1.0.0/3062f220823930cffde7976b694aa67bac3b06c322a02ced92d3761519810ce4)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"07fd23e25b6b4a34a8aeb64a26c0811e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["['DNA: IL-2 gene', 'Protein: NF-kappa B', 'Protein: CD28', 'Protein: 5-lipoxygenase']\n","['Protein: CD28 surface receptor', 'Protein: interleukin-2', 'Protein: IL-2']\n","['Cell_type: primary T lymphocytes', 'Protein: CD28', 'Protein: CD28', 'Protein: NF-kappa B', 'Protein: CD28-responsive complex', 'Protein: IL-2']\n","['Protein: CD28', 'Protein: protein tyrosine kinase', 'Protein: phospholipase A2', 'Protein: 5-lipoxygenase']\n","['Protein: lipoxygenase metabolites', 'Protein: IL-2', 'Protein: NF-kappa B']\n","['Protein: CD28']\n","['DNA: peri-kappa B site', 'DNA: human immunodeficiency virus type 2 enhancer', 'Cell_type: monocytes', 'Cell_type: T cells']\n","[]\n","[]\n","['DNA: enhancer/promoter region']\n"]},{"name":"stderr","output_type":"stream","text":["/Users/maxhager/.virtualenvs/thesis/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n","For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n","- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n","- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n","- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n","  warnings.warn(\n"]}],"source":["from datasets import DatasetDict, Dataset\n","\n","jnlpba = load_dataset('jnlpba', split=['train[:10]', \"validation[:10]\"])\n","jnlpba = DatasetDict({\"train\": jnlpba[0], \"validation\": jnlpba[1]})\n","\n","class JnlpbDataset(Dataset):\n","\n","    def __init__(self, tokenizer, dataset, type_path, max_len=512):\n","        self.dataset = dataset[type_path]\n","        self.max_len = max_len\n","        self.tokenizer = tokenizer\n","        # todo make sure i dont need this\n","        self.tokenizer.max_length = max_len\n","        self.tokenizer.model_max_length = max_len\n","        self.inputs = []\n","        self.targets = []\n","        self.merge()\n","        self.convert()\n","        self._build()\n","        \n","    def __len__(self):\n","        return len(self.inputs)\n","    \n","    def __getitem__(self, index):\n","        source_ids = self.inputs[index][\"input_ids\"].squeeze()\n","        target_ids = self.targets[index][\"input_ids\"].squeeze()\n","\n","        src_mask    = self.inputs[index][\"attention_mask\"].squeeze()  # might need to squeeze\n","        target_mask = self.targets[index][\"attention_mask\"].squeeze()  # might need to squeeze\n","\n","        #tokens = self.datatset.tokens[index]  # add this line\n","        #tokens = self.tokenizer.convert_ids_to_tokens(source_ids)\n","        tokens = self.dataset[\"tokens\"]\n","        return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask, \"tokens\": tokens}\n","\n","    def map_tags(self, row):\n","        mapping = {\n","            0: \"O\",\n","            1: \"B-DNA\",\n","            2: \"I-DNA\",\n","            3: \"B-RNA\",\n","            4: \"I-RNA\",\n","            5: \"B-cell_line\",\n","            6: \"I-cell_line\",\n","            7: \"B-cell_type\",\n","            8: \"I-cell_type\",\n","            9: \"B-protein\",\n","            10: \"I-protein\"\n","        }\n","        row['ner_tags'] = [[mapping[tag] for tag in row['ner_tags']]][0]\n","        return row\n","\n","    def convert(self):\n","        df_train = pd.DataFrame(self.dataset)\n","        #df_train = df_train.apply(self.map_tags, axis=1)\n","        l = []\n","        l_temp = []\n","        for i in range(len(df_train)):\n","            for j in range(len(df_train['ner_tags'][i])):\n","              if df_train['ner_tags'][i][j] != \"O\":\n","                l_temp.append(df_train['ner_tags'][i][j] + ': ' + df_train['tokens'][i][j])\n","            l.append(l_temp)\n","            l_temp = []\n","        d = {'spans': l}\n","        df_train = df_train.assign(spans=l)\n","        for i in df_train[\"spans\"]:\n","          print(i)\n","        train = Dataset.from_pandas(df_train)\n","        self.dataset = train\n","        return train\n","    \n","    def merge_tags(self, tags, tokens):\n","      #todo test if this works also in the scenario of having two B- tags side by side\n","      merged_tags = []\n","      merged_tokens = []\n","      i = 0\n","      while i < len(tags):\n","          if tags[i].startswith('B-'):\n","              merged_tag = tags[i][2:]\n","              merged_token = tokens[i]\n","              i += 1\n","              while i < len(tags) and tags[i].startswith('I-'):\n","                  merged_tag += ' ' + tags[i][2:]\n","                  merged_token += ' ' + tokens[i]\n","                  i += 1\n","              merged_tags.append(merged_tag)\n","              merged_tokens.append(merged_token)\n","          else:\n","              merged_tags.append(tags[i])\n","              merged_tokens.append(tokens[i])\n","              i += 1\n","      for i in range(len(merged_tags)):\n","        s = merged_tags[i].split()[0]\n","        #merged_tags[i].split()[0] = \n","        s = s[0].upper() + s[1:]\n","        merged_tags[i] = s\n","      return merged_tags, merged_tokens\n","\n","    def merge(self):\n","      df_train = pd.DataFrame(self.dataset)\n","      df_train = df_train.apply(self.map_tags, axis=1)\n","      df_train[['ner_tags', 'tokens']] = df_train.apply(lambda x: self.merge_tags(x['ner_tags'], x['tokens']), axis=1, result_type='expand')\n","      self.dataset = Dataset.from_pandas(df_train)\n","\n","    def _build(self):\n","      for idx in range(len(self.dataset)):\n","          input_, target = \" \".join(self.dataset[idx][\"tokens\"]), \"; \".join(\n","              self.dataset[idx][\"spans\"])\n","          input_ = input_.lower() + ' </s>'\n","          target = target.lower() + \" </s>\"\n","\n","          tokenized_inputs = self.tokenizer.batch_encode_plus(\n","              [input_], max_length=self.max_len, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n","          )\n","\n","          tokenized_targets = self.tokenizer.batch_encode_plus(\n","              [target], max_length=self.max_len, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n","          )\n","          self.inputs.append(tokenized_inputs)\n","          self.targets.append(tokenized_targets)\n","\n","tokenizer = AutoTokenizer.from_pretrained('t5-small')\n","\n","input_dataset = JnlpbDataset(tokenizer=tokenizer, dataset=jnlpba, type_path='train')"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1673099480123,"user":{"displayName":"Max Hager","userId":"17820186552942690415"},"user_tz":-60},"id":"ZVzG0fh1UZ5Y","outputId":"0a99d032-57de-4854-99fd-5f6290206cf4"},"outputs":[{"data":{"text/plain":["'for i in range(len(input_dataset)):\\n    _ = input_dataset[i]'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["'''for i in range(len(input_dataset)):\n","    _ = input_dataset[i]'''"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":0,"status":"ok","timestamp":1673099480208,"user":{"displayName":"Max Hager","userId":"17820186552942690415"},"user_tz":-60},"id":"qilcQczaUZ5Y","outputId":"201be77f-5e9f-40ca-b3d9-4bae2537d955"},"outputs":[{"data":{"text/plain":["'data = input_dataset[0]\\n\\nprint(tokenizer.decode(data[\"source_ids\"], skip_special_tokens=False))\\nprint(tokenizer.decode(data[\"target_ids\"], skip_special_tokens=False))'"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["'''data = input_dataset[0]\n","\n","print(tokenizer.decode(data[\"source_ids\"], skip_special_tokens=False))\n","print(tokenizer.decode(data[\"target_ids\"], skip_special_tokens=False))'''"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["308ce58d8c424310842f9d3e825a84b7","13dfe00586ca4db8b105659825c9695d","93fc274c1ea34a0ebf03e9965de84fd0","6acf4cad08ae4c2290e99336e04f8906","af21012d0e9341da9a559e39c49a9beb","659b7b033b6f42a68d0c6b9599f51428","ad456d61621d49e09b61c74b3fbb3f1a","a6dfcc20949d434cb38d2caa56acf958","fe444eac38af4dd5b8854005db712bc7","c328272ecf8c476eb6beb8af43c7c88e","afbbe85f472b4e65bfbfa4c3e738ca4e"]},"executionInfo":{"elapsed":10071,"status":"ok","timestamp":1673099490192,"user":{"displayName":"Max Hager","userId":"17820186552942690415"},"user_tz":-60},"id":"Qr2IJMrIUZ5Y","outputId":"002ec768-bc8f-4f5a-9a33-7575e93d2529"},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/maxhager/.virtualenvs/thesis/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n","For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n","- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n","- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n","- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n","  warnings.warn(\n"]}],"source":["args = argparse.Namespace(**args_dict)\n","model = T5FineTuner(args)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"dVIV1HbOUZ5Z"},"outputs":[],"source":["checkpoint_callback = pl.callbacks.ModelCheckpoint(\n","    filename=args.output_dir+\"/checkpoint.pth\", monitor=\"val_loss\", mode=\"min\", save_top_k=5\n",")\n","\n","train_params = dict(\n","    accumulate_grad_batches=args.gradient_accumulation_steps,\n","    #accelerator='gpu',\n","    #gpus=args.n_gpu,\n","    max_epochs=args.num_train_epochs,\n","    #early_stop_callback=False,\n","    precision=32,\n","    #amp_level=args.opt_level,\n","    gradient_clip_val=args.max_grad_norm,\n","    #checkpoint_callback=checkpoint_callback,\n","    callbacks=[checkpoint_callback, LoggingCallback()],\n",")"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"6B2SgQ3VUZ5Z"},"outputs":[],"source":["def get_dataset(tokenizer, type_path, args):\n","    tokenizer.max_length = args.max_seq_length\n","    tokenizer.model_max_length = args.max_seq_length\n","    jnlpba = load_dataset('jnlpba', split=['train[:10]', \"validation[:10]\"])\n","    jnlpba = DatasetDict({\"train\": jnlpba[0], \"validation\": jnlpba[1]})\n","    dataset = jnlpba\n","    return JnlpbDataset(tokenizer=tokenizer, dataset=dataset, type_path=type_path)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1673099490195,"user":{"displayName":"Max Hager","userId":"17820186552942690415"},"user_tz":-60},"id":"WoAI_CIHUZ5Z","outputId":"1f01f16b-8eb4-4f42-be15-ced99c6616e3"},"outputs":[{"name":"stderr","output_type":"stream","text":["GPU available: True (mps), used: False\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","/Users/maxhager/.virtualenvs/thesis/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:200: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n","  rank_zero_warn(\n"]}],"source":["trainer = pl.Trainer(**train_params)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":472,"referenced_widgets":["c1bd319c1d394a3595a34a7c17adea07","f75e0f5fcad947baa6353bf2b4fe81cb","3dda6b69c20a43fa8166c6aef077b5d5","8b3951c85bd74b668c3094c31029c72a","ac5eb07253b746aba1d5e084fffc61ac","557bbbf65f0447edae3f4275d9fdfcfd","52dc301529d647cd99743e227e964457","d4a9cd938011412fb7a36d5850f60056","e30f6ce4fef949efaa11b06a6edc1a63","d7061b0bbaf6458ca9518f3a67cb6fd1","1d347a76c2f648c2897c24bbd6e270e1","93dfb127f3684234a009164edacb7b89","bfa2aa1fffb7413096f5716dbc3fae9a","21be4a80c2824249a26a73c00a063427","9802821e7b2341cca9f3be4283688120","191793bf1c954a4094e658923b8d7ea0","7c8a31fb9dea4c709a25fcaf2bd7ccf2","bcc6009bc67b4a5f9b24f67652690af5","0ee1dc4cc8484ee7b1586a2dd6fabd64","537faac266c74412a45fc025847d1d5e","04bb1f580b0e4430b97a4be5a8015d11","fa3d9216d1a84191b7338946619a9769","747f8ef28c894212b638e0f2228692e2","10a02524699d4a85966d7347eceb242f","cd65ae9aa2ce42beb252abf37a224fb6","05803d675e7c49d1a2e94e82183b8a6c","618993de1f5d4306aba1ea17a55ca811","c9f00ac026fd4a4588f3aebf056607b3","2f91866e03914919ae527782c6cd1b09","cea5530aad974e379098d320bde565f8","56cd73ac22f9482c98c47ecfbc79fd22","1399da62475043d8a2c1b5e35bf063db","81c5cbfcca2f495282a2ef0a9e59aa3b","5bde5f887a4b4453b1c7f063571eebf5","3ddf0d93e284407c9d5487aba1075a1b","b39d9d4171aa4ac3901f3f565dbdedb9","ed58aa2dbf014ba397dd3dfc92748f4f","d81b53cabf644fb888003bb5226b4b69","8b809477682c49a8bc7ecfb8edef0a37","fd2b69e1f33c457ea789eb9ae5a95951","6412440adaf24a1f89385f50f3c27cbe","ae6a42abd7bc4251836976922330d02e","e44553f939c2420f989debe0d85890c6","d2795d6eb6db498e843f36064a151496","6aeb25c4ca724ceb837ff3d3d9e34bbd","e96ccdf826914c908e4bd2c2d65097fc","f8382a174e324beaac03ccb096ed42b0","a9d9060d50874a58b9fb3c947a01e552","318fcef6589c4d1b866f66d774a86a43","687e9859f5054ac9965ce1fdfe10335f","1cc7e51154004f1c8ab939f2d519aa86","aae1252dfd084067987adb777127fa83","2f745a3b464d43d9970496fbaa96a9d5","8d3ba9e01f5747d7a8f8ca32c65853eb","e40b957f198b48099a55d684cd6c4df5","b0f4ec4e56ce461dad9eae3e8bfa8542","5f530bc9d6474de3919d0e157a7a043d","f417fe0f56b1419eb393d4b9bb7cac4f","7f2f18313a9b48a281b742f765eee68a","abea09c7219b48e691287df0a2a8a689","10bb57b11c22494e96ff8932f6faf929","c3ba56b10be24daf8601d5f765b11531","0aa8f40b4d974319ae78a03fcdd7ef05","9e05266880874bc297ea8daff5b6d064","e108d8cfdce84a9386c60a57c0ccdc91","446da3c205564ab5a44bb7e9d99d4737","c7d661c87ffa41cd994f23e0468b872f"]},"id":"flAVWfevUZ5Z","outputId":"c22eced5-062b-4985-c195-35103c971fbe"},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/maxhager/.virtualenvs/thesis/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:92: UserWarning: When using `Trainer(accumulate_grad_batches != 1)` and overriding `LightningModule.optimizer_{step,zero_grad}`, the hooks will not be called on every batch (rather, they are called on every optimization step).\n","  rank_zero_warn(\n","/Users/maxhager/.virtualenvs/thesis/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\n","  | Name  | Type                       | Params\n","-----------------------------------------------------\n","0 | model | T5ForConditionalGeneration | 60.5 M\n","-----------------------------------------------------\n","60.5 M    Trainable params\n","0         Non-trainable params\n","60.5 M    Total params\n","242.026   Total estimated model params size (MB)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"951b8f7fe70a46028a8fafc0aa140e42","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Found cached dataset jnlpba (/Users/maxhager/.cache/huggingface/datasets/jnlpba/jnlpba/1.0.0/3062f220823930cffde7976b694aa67bac3b06c322a02ced92d3761519810ce4)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dae0e65b61fa460fa592f3175ab1c148","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["['Protein: glucocorticoid receptors', 'Cell_type: lymphocytes']\n","['Protein: glucocorticoid receptors', 'Protein: GR', 'Cell_type: peripheral blood lymphocytes']\n","['Cell_type: lymphocytes', 'Protein: GR', 'Cell_type: control cells']\n","['Protein: GR']\n","['Cell_type: lymphocytes', 'Protein: GR']\n","['Protein: 1 , 25-Dihydroxyvitamin D3 receptors', 'Cell_type: lymphocytes', 'Cell_type: T- and B-lymphocyte']\n","['Cell_type: lymphocytes']\n","[]\n","['Cell_type: T lymphocytes']\n","[]\n"]},{"name":"stderr","output_type":"stream","text":["/Users/maxhager/.virtualenvs/thesis/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  rank_zero_warn(\n"]},{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stderr","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"<string>\", line 1, in <module>\n","  File \"/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n","    exitcode = _main(fd, parent_sentinel)\n","  File \"/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n","    self = reduction.pickle.load(from_parent)\n","AttributeError: Can't get attribute 'JnlpbDataset' on <module '__main__' (built-in)>\n"]}],"source":["trainer.fit(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"XqsK8RkhUZ5Z"},"outputs":[],"source":["# add wandb logger\n","# push to hf hub\n","# metrics \n","#next steps\n","#!rm -r \"/content/lightning_logs\""]},{"cell_type":"markdown","metadata":{"id":"c4tZi-U_aA7Z"},"source":["### Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ZmwG6bSdaAmx"},"outputs":[],"source":["model = model.load_from_checkpoint(\"/content/lightning_logs/version_0/checkpoints/checkpoints/checkpoint.pth.ckpt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["b2fbd66af085401491688285b2dfb5e1"]},"executionInfo":{"elapsed":10833,"status":"ok","timestamp":1673085846393,"user":{"displayName":"Max Wobbert","userId":"06396045437441764532"},"user_tz":-60},"id":"NU4lH2W2tBCH","outputId":"9cfd2391-c3ab-475e-eb62-24519f4d3d06"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:datasets.builder:Found cached dataset jnlpba (/root/.cache/huggingface/datasets/jnlpba/jnlpba/1.0.0/3062f220823930cffde7976b694aa67bac3b06c322a02ced92d3761519810ce4)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b2fbd66af085401491688285b2dfb5e1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1387: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["text: consistent with these differences , we have previously demonstrated that the enhancer/promoter\n","region of hiv-2 functions quite differently from that of hiv-1 .\n","\n","Actual Entities: b-dna: enhancer/promoter; i-dna: region\n","Predicted Entities: Wir haben bereits gezeigt, dass die enhancing/promoter region hiv-2 sehr unterschiedlich\n","=====================================================================\n","\n","text: our data suggest that lipoxygenase metabolites activate roi formation which then induce il-2\n","expression via nf-kappa b activation .\n","\n","Actual Entities: b-protein: lipoxygenase; i-protein: metabolites; b-protein: il-2; b-protein: nf-kappa; i-protein: b\n","Predicted Entities: data suggest that lipoxygenase metabolites activate roi formation\n","=====================================================================\n","\n","text: hiv-1 and hiv-2 display significant differences in nucleic acid sequence and in the natural\n","history of clinical disease .\n","\n","Actual Entities: \n","Predicted Entities: hiv-1 et hiv-2 présentent signifikante Unterschiede in\n","=====================================================================\n","\n","text: these findings should be useful for therapeutic strategies and the development of\n","immunosuppressants targeting the cd28 costimulatory pathway .\n","\n","Actual Entities: b-protein: cd28\n","Predicted Entities: Diese Ergebnisse sollten nützlich sein für die Therapiestrategien und die Entwicklung von immunosuppressants\n","=====================================================================\n","\n","text: activation of the cd28 surface receptor provides a major costimulatory signal for t cell\n","activation resulting in enhanced production of interleukin-2 ( il-2 ) and cell proliferation .\n","\n","Actual Entities: b-protein: cd28; i-protein: surface; i-protein: receptor; b-protein: interleukin-2; b-protein: il-2\n","Predicted Entities: Die aktivation des cd28 surface receptors bietet ein wichtiges costimul\n","=====================================================================\n","\n","text: human immunodeficiency virus type 2 ( hiv-2 ) , like hiv-1 , causes aids and is associated\n","with aids cases primarily in west africa .\n","\n","Actual Entities: \n","Predicted Entities: , a virus d'hygiène et de l\n","=====================================================================\n","\n","text: il-2 gene expression and nf-kappa b activation through cd28 requires reactive oxygen\n","production by 5-lipoxygenase .\n","\n","Actual Entities: b-dna: il-2; i-dna: gene; b-protein: nf-kappa; i-protein: b; b-protein: cd28; b-protein: 5-lipoxygenase\n","Predicted Entities: Die il-2 gene expression und die nf-kappa b activation\n","=====================================================================\n","\n","text: delineation of the cd28 signaling cascade was found to involve protein tyrosine kinase\n","activity , followed by the activation of phospholipase a2 and 5-lipoxygenase .\n","\n","Actual Entities: b-protein: cd28; b-protein: protein; i-protein: tyrosine; i-protein: kinase; b-protein: phospholipase; i-protein: a2; b-protein: 5-lipoxygenase\n","Predicted Entities: On a constaté que la delimitation de la cascade de signalisation c\n","=====================================================================\n","\n","text: the peri-kappa b site mediates human immunodeficiency virus type 2 enhancer activation in\n","monocytes but not in t cells .\n","\n","Actual Entities: b-dna: peri-kappa; i-dna: b; i-dna: site; b-dna: human; i-dna: immunodeficiency; i-dna: virus; i-dna: type; i-dna: 2; i-dna: enhancer; b-cell_type: monocytes; b-cell_type: t; i-cell_type: cells\n","Predicted Entities: peri-kappa b site mediates human immunodeficiency virus\n","=====================================================================\n","\n","text: in primary t lymphocytes we show that cd28 ligation leads to the rapid intracellular formation\n","of reactive oxygen intermediates ( rois ) which are required for cd28 -mediated activation of the\n","nf-kappa b / cd28-responsive complex and il-2 expression .\n","\n","Actual Entities: b-cell_type: primary; i-cell_type: t; i-cell_type: lymphocytes; b-protein: cd28; b-protein: cd28; b-protein: nf-kappa; i-protein: b; b-protein: cd28-responsive; i-protein: complex; b-protein: il-2\n","Predicted Entities: , we show that cd28 ligation leads to the rapid intracellular formation\n","=====================================================================\n","\n"]}],"source":["import textwrap\n","jnlpba = load_dataset('jnlpba', split=['train[:10]', \"validation[:10]\"])\n","jnlpba = DatasetDict({\"train\": jnlpba[0], \"validation\": jnlpba[1]})\n","input_dataset = JnlpbDataset(tokenizer=tokenizer, dataset=jnlpba, type_path='train')\n","\n","dataloader = DataLoader(input_dataset, batch_size=32, num_workers=2, shuffle=True)\n","model.model.eval()\n","model = model.to(\"cpu\")\n","outputs = []\n","targets = []\n","texts = []\n","\n","#catched in \n","#i want to check if the text and the predicted entities are alright\n","#i need to change the representation of the entities. \n","for batch in dataloader:\n","    outs = model.model.generate(input_ids=batch['source_ids'],\n","                                attention_mask=batch['source_mask'])\n","    dec = [tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False).strip() for ids in outs]\n","    target = [tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False).strip()\n","                for ids in batch[\"target_ids\"]]\n","    text = [tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False).strip()\n","                for ids in batch[\"source_ids\"]]\n","    texts.extend(text)\n","    outputs.extend(dec)\n","    targets.extend(target)\n","    break\n","\n","for i in range(10):\n","    c = texts[i]\n","    lines = textwrap.wrap(\"text:\\n%s\\n\" % c, width=100)\n","    print(\"\\n\".join(lines))\n","    print(\"\\nActual Entities: %s\" % target[i])\n","    print(\"Predicted Entities: %s\" % outputs[i])\n","    print(\"=====================================================================\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"N6vb-QrEtSF6"},"outputs":[],"source":["def find_sub_list(sl, l):\n","    results = []\n","    sll = len(sl)\n","    for ind in (i for i, e in enumerate(l) if e == sl[0]):\n","        if l[ind:ind+sll] == sl:\n","            results.append((ind, ind+sll-1))\n","    return results\n","\n","def generate_label(input: str, target: str):\n","    mapper = {\n","        \"O\": 0,\n","        \"B-DNA\": 1,\n","        \"I-DNA\": 2,\n","        \"B-RNA\": 3,\n","        \"I-RNA\": 4,\n","        \"B-cell_line\": 5,\n","        \"I-cell_line\": 6,\n","        \"B-cell_type\": 7,\n","        \"I-cell_type\": 8,\n","        \"B-protein\": 9,\n","        \"I-protein\": 10\n","    }\n","\n","    mapper_2 = {k.lower(): k for k in mapper.keys()}\n","\n","    input = input.split(\" \")\n","\n","    target = target.split(\"; \")\n","\n","    init_target_label = [mapper[\"O\"]] * len(input)\n","\n","    for ent in target:\n","        ent = ent.split(\": \")\n","        try:\n","            sent_end = ent[1].split(\" \")\n","            index = find_sub_list(sent_end, input)\n","        except:\n","            continue\n","        try:\n","            init_target_label[index[0][0]] = mapper_2[ent[0]] #mapper[f\"B-{ent[0]}\"]\n","            for i in range(index[0][0]+1, index[0][1]+1):\n","                init_target_label[i] = mapper_2[ent[0]] #mapper[f\"I-{ent[0]}\"]\n","        except:\n","            continue\n","\n","    return init_target_label"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1052,"status":"ok","timestamp":1673100956921,"user":{"displayName":"Max Hager","userId":"17820186552942690415"},"user_tz":-60},"id":"9zzuW1_uLwxW","outputId":"c8435b55-e81c-4148-96f4-b4ed9a474ae5"},"outputs":[{"name":"stdout","output_type":"stream","text":["[['gen2', 'gene'], ['CD28', 'protein']]\n"]}],"source":["l = []\n","strings = [\"B-DNA: gen2, I-DNA: gene\", \"B-protein: CD28, B-protein: protein\"]\n","\n","for string in strings:\n","    sublist = []\n","    for item in string.split(\", \"):\n","        sublist.append(item.split(\": \")[1])\n","    l.append(sublist)\n","\n","#need to catch index errors\n","\n","print(l)\n"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":564},"executionInfo":{"elapsed":1148,"status":"error","timestamp":1673101039145,"user":{"displayName":"Max Hager","userId":"17820186552942690415"},"user_tz":-60},"id":"zSJT6wRMt2kD","outputId":"f4a7280a-5356-4b41-9aa5-7ffabd263f8c"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Protein: glucocorticoid receptors', 'Cell_type: lymphocytes']\n","['Protein: glucocorticoid receptors', 'Protein: GR', 'Cell_type: peripheral blood lymphocytes']\n","['Cell_type: lymphocytes', 'Protein: GR', 'Cell_type: control cells']\n","['Protein: GR']\n","['Cell_type: lymphocytes', 'Protein: GR']\n","['Protein: 1 , 25-Dihydroxyvitamin D3 receptors', 'Cell_type: lymphocytes', 'Cell_type: T- and B-lymphocyte']\n","['Cell_type: lymphocytes']\n","[]\n","['Cell_type: T lymphocytes']\n","[]\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A"]},{"name":"stdout","output_type":"stream","text":["[['Number', 'of', 'glucocorticoid receptors', 'in', 'lymphocytes', 'and', 'their', 'sensitivity', 'to', 'hormone', 'action', '.'], ['The', 'study', 'demonstrated', 'a', 'decreased', 'level', 'of', 'glucocorticoid receptors', '(', 'GR', ')', 'in', 'peripheral blood lymphocytes', 'from', 'hypercholesterolemic', 'subjects', ',', 'and', 'an', 'elevated', 'level', 'in', 'patients', 'with', 'acute', 'myocardial', 'infarction', '.'], ['In', 'the', 'lymphocytes', 'with', 'a', 'high', 'GR', 'number', ',', 'dexamethasone', 'inhibited', '[', '3H', ']', '-thymidine', 'and', '[', '3H', ']', '-acetate', 'incorporation', 'into', 'DNA', 'and', 'cholesterol', ',', 'respectively', ',', 'in', 'the', 'same', 'manner', 'as', 'in', 'the', 'control cells', '.'], ['On', 'the', 'other', 'hand', ',', 'a', 'decreased', 'GR', 'number', 'resulted', 'in', 'a', 'less', 'efficient', 'dexamethasone', 'inhibition', 'of', 'the', 'incorporation', 'of', 'labeled', 'compounds', '.'], ['These', 'data', 'showed', 'that', 'the', 'sensitivity', 'of', 'lymphocytes', 'to', 'glucocorticoids', 'changed', 'only', 'with', 'a', 'decrease', 'of', 'GR', 'level', '.'], ['[', '1 , 25-Dihydroxyvitamin D3 receptors', 'in', 'lymphocytes', 'and', 'T- and B-lymphocyte', 'count', 'in', 'patients', 'with', 'glomerulonephritis', ']'], ['Content', 'of', 'receptors', 'to', 'hormonal', 'form', 'of', 'vitamin', 'D3', ',', '1.25', '(', 'OH', ')', '2D3', ',', 'constituted', '27.3', 'fmole/mg', 'of', 'protein', 'in', 'lymphocytes', 'of', 'peripheric', 'blood', 'of', 'children', 'with', 'glomerulonephritis', '.'], ['In', 'the', 'patients', 'concentration', 'of', 'total', 'and', 'ionized', 'form', 'of', 'Ca2+', 'was', 'decreased', 'down', 'to', '2.04', 'mmole/L', 'and', '1.09', 'mmole/L', ',', 'respectively', ',', 'while', 'an', 'increase', 'in', 'parathormone', '(', 'PTH', ')', 'by', '36', '%', 'and', 'a', 'distinct', 'decrease', 'in', '25', '(', 'OH', ')', 'D', 'concentration', '(', 'lower', 'than', '1.25', 'ng/ml', ')', 'was', 'found', 'in', 'blood', ';', 'content', 'of', 'cAMP', 'was', 'also', 'decreased', 'in', 'lymphocytes', 'by', '33', '%', '.'], ['At', 'the', 'same', 'time', ',', 'total', 'content', 'of', 'T lymphocytes', 'was', 'decreased', '1.5-fold', 'in', 'peripheric', 'blood', '.'], ['Treatment', 'with', 'I-hydroxyvitamin', 'D3', '(', '1-1.5', 'mg', 'daily', ',', 'within', '4', 'weeks', ')', 'led', 'to', 'normalization', 'of', 'total', 'and', 'ionized', 'form', 'of', 'Ca2+', 'and', 'of', '25', '(', 'OH', ')', 'D', ',', 'but', 'did', 'not', 'affect', 'the', 'PTH', 'content', 'in', 'blood', '.']]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1387: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","  0%|          | 0/1 [00:00<?, ?it/s]\n"]},{"ename":"IndexError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-92f02ca7fee9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0msublist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\", \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0msublist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\": \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msublist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}],"source":["from tqdm import tqdm\n","\n","test_dataset = JnlpbDataset(tokenizer=tokenizer, dataset=jnlpba, type_path='validation')\n","\n","test_loader = DataLoader(test_dataset, batch_size=32,\n","                             num_workers=2, shuffle=True)\n","model.model.eval()\n","model = model.to(\"cuda\")\n","outputs = []\n","targets = []\n","all_text = []\n","true_labels = []\n","pred_labels = []\n","predictions = []\n","predictions_temp = []\n","counter = 0\n","for batch in tqdm(test_loader):\n","    tokens = []\n","    t = []\n","    for token_tuple in batch[\"tokens\"]:\n","      for i in token_tuple:\n","        t.append(i[0])\n","      tokens.append(t)\n","      t = []\n","    print(tokens)\n","    #okay now finally i have the desired state \n","    #next step is to extract all the values\n","    #format is [B-DNA: IL-2, I-DNA: gene, B-protein: NF-kappa]\n","    #how can I get [IL-2, gene..]?\n","\n","    counter += 1\n","    input_ids = batch['source_ids'].to(\"cuda\")\n","    attention_mask = batch['source_mask'].to(\"cuda\")\n","    outs = model.model.generate(input_ids=input_ids,\n","                                attention_mask=attention_mask)\n","\n","    #thet\n","    dec = [tokenizer.decode(ids, skip_special_tokens=True,\n","                            clean_up_tokenization_spaces=False).strip() for ids in outs]\n","\n","    l = []\n","\n","    for s in dec:\n","        sublist = []\n","        for item in s.split(\", \"):\n","          try:\n","            sublist.append(item.split(\": \")[1])\n","          except IndexError:\n","            pass\n","        l.append(sublist)\n","    print(l)\n","\n","    #i have a list\n","    #iter over list and extract \n","    target = [tokenizer.decode(ids, skip_special_tokens=True,  clean_up_tokenization_spaces=False).strip()\n","                for ids in batch[\"target_ids\"]]\n","    texts = [tokenizer.decode(ids, skip_special_tokens=True,  clean_up_tokenization_spaces=False).strip()\n","                for ids in batch[\"source_ids\"]]\n","\n","    true_label = [generate_label(texts[i].strip(), target[i].strip()) if target[i].strip() != 'none' else [\n","        \"O\"]*len(texts[i].strip().split()) for i in range(len(texts))]\n","    \n","    pred_label = [generate_label(texts[i].strip(), dec[i].strip()) if dec[i].strip() != 'none' else [\n","        \"O\"]*len(texts[i].strip().split()) for i in range(len(texts))]\n","\n","    outputs.extend(dec)\n","    targets.extend(target)\n","    true_labels.extend(true_label)\n","    pred_labels.extend(pred_label)\n","    all_text.extend(texts)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1673085847654,"user":{"displayName":"Max Wobbert","userId":"06396045437441764532"},"user_tz":-60},"id":"7cB40VaXueRA","outputId":"2484f790-d574-4605-d5f8-3e271b1edb5d"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'on the other hand , a decreased gr number resulted in a less efficient dexamethasone inhibition of the incorporation of labeled compounds .'"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["all_text[4]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e38bf2e4e49e4c218cf4b2f71616184a"]},"executionInfo":{"elapsed":670,"status":"ok","timestamp":1673085848317,"user":{"displayName":"Max Wobbert","userId":"06396045437441764532"},"user_tz":-60},"id":"1wDzh1Sguh4T","outputId":"75f9fc51-3dab-4b52-ed50-b17ab8c21d5e"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-22-e55a46f3ca80>:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n","  metric = load_metric(\"seqeval\")\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e38bf2e4e49e4c218cf4b2f71616184a","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/2.47k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Text:  [ 1 , 25-dihydroxyvitamin d3 receptors in lymphocytes and t- and b-lymphocyte count in patients with glomerulonephritis ]\n","targets:  glomerulonephritis ]\n","Predicted Token Class:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","True Token Class:  [0, 'B-protein', 'I-protein', 'I-protein', 'I-protein', 'I-protein', 0, 'B-cell_type', 'I-cell_type', 'B-cell_type', 0, 'I-cell_type', 0, 0, 0, 0, 0, 0]\n","=====================================================================\n","\n","Text:  content of receptors to hormonal form of vitamin d3 , 1.25 ( oh ) 2d3 , constituted 27.3 fmole/mg of protein in lymphocytes of peripheric blood of children with glomerulonephritis .\n","targets:  , d3 , 1,25 ( oh ) 2d3\n","Predicted Token Class:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","True Token Class:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 'B-cell_type', 0, 0, 0, 0, 0, 0, 0, 0]\n","=====================================================================\n","\n","Text:  the study demonstrated a decreased level of glucocorticoid receptors ( gr ) in peripheral blood lymphocytes from hypercholesterolemic subjects , and an elevated level in patients with acute myocardial infarction .\n","targets:  , and a higher level in patients with acute myocardial infarction\n","Predicted Token Class:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","True Token Class:  [0, 0, 0, 0, 0, 0, 0, 'B-protein', 'I-protein', 0, 'B-protein', 0, 0, 'B-cell_type', 'I-cell_type', 'I-cell_type', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","=====================================================================\n","\n","Text:  in the patients concentration of total and ionized form of ca2+ was decreased down to 2.04 mmole/l and 1.09 mmole/l , respectively , while an increase in parathormone ( pth ) by 36 % and a distinct decrease in 25 ( oh ) d concentration ( lower than 1.25 ng/ml ) was found in blood ; content of camp was also decreased in lymphocytes by 33 % .\n","targets:  , compared to 1,09 mmole/l , respectively .\n","Predicted Token Class:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","True Token Class:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","=====================================================================\n","\n","Text:  on the other hand , a decreased gr number resulted in a less efficient dexamethasone inhibition of the incorporation of labeled compounds .\n","targets:  , a decreased gr number resulted in a less efficient dexamet\n","Predicted Token Class:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","True Token Class:  [0, 0, 0, 0, 0, 0, 0, 'B-protein', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","=====================================================================\n","\n","Text:  at the same time , total content of t lymphocytes was decreased 1.5-fold in peripheric blood .\n","targets:  Gleichzeitig wurde der totale Inhalt von t lymphocytes um 1,5 % in pe\n","Predicted Token Class:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","True Token Class:  [0, 0, 0, 0, 0, 0, 0, 0, 'B-cell_type', 'I-cell_type', 0, 0, 0, 0, 0, 0, 0]\n","=====================================================================\n","\n","Text:  treatment with i-hydroxyvitamin d3 ( 1-1.5 mg daily , within 4 weeks ) led to normalization of total and ionized form of ca2+ and of 25 ( oh ) d , but did not affect the pth content in blood .\n","targets:  i-hydroxyvitamin d3 ( 1-1.5 mg daily , within 4\n","Predicted Token Class:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","True Token Class:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","=====================================================================\n","\n","Text:  these data showed that the sensitivity of lymphocytes to glucocorticoids changed only with a decrease of gr level .\n","targets:  Diese Daten haben gezeigt, dass die Sensibilität der lymphocytes zu gluco\n","Predicted Token Class:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","True Token Class:  [0, 0, 0, 0, 0, 0, 0, 'B-cell_type', 0, 0, 0, 0, 0, 0, 0, 0, 'B-protein', 0, 0]\n","=====================================================================\n","\n","Text:  number of glucocorticoid receptors in lymphocytes and their sensitivity to hormone action .\n","targets:  receptors in lymphocytes and their sensitivity to hormone action .\n","Predicted Token Class:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","True Token Class:  [0, 0, 'B-protein', 'I-protein', 0, 'B-cell_type', 0, 0, 0, 0, 0, 0, 0]\n","=====================================================================\n","\n","Text:  in the lymphocytes with a high gr number , dexamethasone inhibited [ 3h ] -thymidine and [ 3h ] -acetate incorporation into dna and cholesterol , respectively , in the same manner as in the control cells .\n","targets:  , in the lymphocytes with a high gr number , dexa\n","Predicted Token Class:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","True Token Class:  [0, 0, 'B-cell_type', 0, 0, 0, 'B-protein', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 'B-cell_type', 'I-cell_type', 0]\n","=====================================================================\n","\n","{'_': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}, 'cell_type': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 10}, 'protein': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}, 'overall_precision': 0.0, 'overall_recall': 0.0, 'overall_f1': 0.0, 'overall_accuracy': 0.9063545150501672}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 0 seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["from datasets import load_metric\n","\n","metric = load_metric(\"seqeval\")\n","\n","for i in range(10):\n","    print(f\"Text:  {all_text[i]}\")\n","    print(f\"targets:  {outputs[i]}\")\n","    print(f\"Predicted Token Class:  {pred_labels[i]}\")\n","    print(f\"True Token Class:  {true_labels[i]}\")\n","    print(\"=====================================================================\\n\")\n","\n","    #Protein: Berlin\n","    #l = [0,0,Berlin,0]\n","\n","print(metric.compute(predictions=pred_labels, references=true_labels))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"y1SIm9Lz22tB"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"thesis","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9 (main, Dec 15 2022, 10:44:50) [Clang 14.0.0 (clang-1400.0.29.202)]"},"vscode":{"interpreter":{"hash":"f68a4539c9a11cef9bf0819cdddedfa00ec9d5fcff3291c5b30fad122c003099"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"04bb1f580b0e4430b97a4be5a8015d11":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05803d675e7c49d1a2e94e82183b8a6c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1399da62475043d8a2c1b5e35bf063db","placeholder":"​","style":"IPY_MODEL_81c5cbfcca2f495282a2ef0a9e59aa3b","value":" 2/2 [00:00&lt;00:00, 50.86it/s]"}},"07050080cdbe4feca8bd9f54fca26537":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0aa8f40b4d974319ae78a03fcdd7ef05":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c4a2dfb4db34a6987218d14fca65671":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e37623fb7cbf4de5bfc4aede2aea8e68","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_07050080cdbe4feca8bd9f54fca26537","value":2}},"0ee1dc4cc8484ee7b1586a2dd6fabd64":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10a02524699d4a85966d7347eceb242f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9f00ac026fd4a4588f3aebf056607b3","placeholder":"​","style":"IPY_MODEL_2f91866e03914919ae527782c6cd1b09","value":"100%"}},"10bb57b11c22494e96ff8932f6faf929":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1399da62475043d8a2c1b5e35bf063db":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13dfe00586ca4db8b105659825c9695d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_659b7b033b6f42a68d0c6b9599f51428","placeholder":"​","style":"IPY_MODEL_ad456d61621d49e09b61c74b3fbb3f1a","value":"Downloading: 100%"}},"191793bf1c954a4094e658923b8d7ea0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1cc7e51154004f1c8ab939f2d519aa86":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d347a76c2f648c2897c24bbd6e270e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"21be4a80c2824249a26a73c00a063427":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ee1dc4cc8484ee7b1586a2dd6fabd64","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_537faac266c74412a45fc025847d1d5e","value":2}},"2f39b3b8167b408e979f99885f0a73be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c06b9f7f34e94b87bc7cc5d240b11623","placeholder":"​","style":"IPY_MODEL_aabb344daf234eee9ca19075a3b56f5b","value":" 2/2 [00:00&lt;00:00, 95.83it/s]"}},"2f745a3b464d43d9970496fbaa96a9d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2f91866e03914919ae527782c6cd1b09":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"308ce58d8c424310842f9d3e825a84b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_13dfe00586ca4db8b105659825c9695d","IPY_MODEL_93fc274c1ea34a0ebf03e9965de84fd0","IPY_MODEL_6acf4cad08ae4c2290e99336e04f8906"],"layout":"IPY_MODEL_af21012d0e9341da9a559e39c49a9beb"}},"318fcef6589c4d1b866f66d774a86a43":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"3dda6b69c20a43fa8166c6aef077b5d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4a9cd938011412fb7a36d5850f60056","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e30f6ce4fef949efaa11b06a6edc1a63","value":2}},"3ddf0d93e284407c9d5487aba1075a1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b809477682c49a8bc7ecfb8edef0a37","placeholder":"​","style":"IPY_MODEL_fd2b69e1f33c457ea789eb9ae5a95951","value":"Epoch 1: 100%"}},"446da3c205564ab5a44bb7e9d99d4737":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"44fc0cc48ec94431a7908b3af5e6ad9b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52dc301529d647cd99743e227e964457":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"537faac266c74412a45fc025847d1d5e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"557bbbf65f0447edae3f4275d9fdfcfd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56cd73ac22f9482c98c47ecfbc79fd22":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5bde5f887a4b4453b1c7f063571eebf5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3ddf0d93e284407c9d5487aba1075a1b","IPY_MODEL_b39d9d4171aa4ac3901f3f565dbdedb9","IPY_MODEL_ed58aa2dbf014ba397dd3dfc92748f4f"],"layout":"IPY_MODEL_d81b53cabf644fb888003bb5226b4b69"}},"5f530bc9d6474de3919d0e157a7a043d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_10bb57b11c22494e96ff8932f6faf929","placeholder":"​","style":"IPY_MODEL_c3ba56b10be24daf8601d5f765b11531","value":"Validation DataLoader 0: 100%"}},"618993de1f5d4306aba1ea17a55ca811":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6412440adaf24a1f89385f50f3c27cbe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"659b7b033b6f42a68d0c6b9599f51428":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"687e9859f5054ac9965ce1fdfe10335f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6acf4cad08ae4c2290e99336e04f8906":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c328272ecf8c476eb6beb8af43c7c88e","placeholder":"​","style":"IPY_MODEL_afbbe85f472b4e65bfbfa4c3e738ca4e","value":" 242M/242M [00:03&lt;00:00, 72.3MB/s]"}},"6aeb25c4ca724ceb837ff3d3d9e34bbd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e96ccdf826914c908e4bd2c2d65097fc","IPY_MODEL_f8382a174e324beaac03ccb096ed42b0","IPY_MODEL_a9d9060d50874a58b9fb3c947a01e552"],"layout":"IPY_MODEL_318fcef6589c4d1b866f66d774a86a43"}},"747f8ef28c894212b638e0f2228692e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_10a02524699d4a85966d7347eceb242f","IPY_MODEL_cd65ae9aa2ce42beb252abf37a224fb6","IPY_MODEL_05803d675e7c49d1a2e94e82183b8a6c"],"layout":"IPY_MODEL_618993de1f5d4306aba1ea17a55ca811"}},"7c8a31fb9dea4c709a25fcaf2bd7ccf2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f2f18313a9b48a281b742f765eee68a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e108d8cfdce84a9386c60a57c0ccdc91","placeholder":"​","style":"IPY_MODEL_446da3c205564ab5a44bb7e9d99d4737","value":" 2/2 [00:00&lt;00:00, 25.02it/s]"}},"81c5cbfcca2f495282a2ef0a9e59aa3b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b3951c85bd74b668c3094c31029c72a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7061b0bbaf6458ca9518f3a67cb6fd1","placeholder":"​","style":"IPY_MODEL_1d347a76c2f648c2897c24bbd6e270e1","value":" 2/2 [00:02&lt;00:00,  1.46s/it]"}},"8b809477682c49a8bc7ecfb8edef0a37":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d3ba9e01f5747d7a8f8ca32c65853eb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"905065f70d2846c0b3ffd43edb9d209b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44fc0cc48ec94431a7908b3af5e6ad9b","placeholder":"​","style":"IPY_MODEL_e14ebba3c7024183aac18b2d61c280c1","value":"100%"}},"93dfb127f3684234a009164edacb7b89":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bfa2aa1fffb7413096f5716dbc3fae9a","IPY_MODEL_21be4a80c2824249a26a73c00a063427","IPY_MODEL_9802821e7b2341cca9f3be4283688120"],"layout":"IPY_MODEL_191793bf1c954a4094e658923b8d7ea0"}},"93fc274c1ea34a0ebf03e9965de84fd0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6dfcc20949d434cb38d2caa56acf958","max":242065649,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fe444eac38af4dd5b8854005db712bc7","value":242065649}},"9802821e7b2341cca9f3be4283688120":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04bb1f580b0e4430b97a4be5a8015d11","placeholder":"​","style":"IPY_MODEL_fa3d9216d1a84191b7338946619a9769","value":" 2/2 [00:00&lt;00:00, 76.88it/s]"}},"9e05266880874bc297ea8daff5b6d064":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a6dfcc20949d434cb38d2caa56acf958":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a948414581d94776b6d4e4dc5ad95023":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_905065f70d2846c0b3ffd43edb9d209b","IPY_MODEL_0c4a2dfb4db34a6987218d14fca65671","IPY_MODEL_2f39b3b8167b408e979f99885f0a73be"],"layout":"IPY_MODEL_cc15cd85d45b4fd89db6397133faeee8"}},"a9d9060d50874a58b9fb3c947a01e552":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d3ba9e01f5747d7a8f8ca32c65853eb","placeholder":"​","style":"IPY_MODEL_e40b957f198b48099a55d684cd6c4df5","value":" 2/2 [00:00&lt;00:00, 24.26it/s]"}},"aabb344daf234eee9ca19075a3b56f5b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aae1252dfd084067987adb777127fa83":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abea09c7219b48e691287df0a2a8a689":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"ac5eb07253b746aba1d5e084fffc61ac":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"ad456d61621d49e09b61c74b3fbb3f1a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae6a42abd7bc4251836976922330d02e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"af21012d0e9341da9a559e39c49a9beb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afbbe85f472b4e65bfbfa4c3e738ca4e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b0f4ec4e56ce461dad9eae3e8bfa8542":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5f530bc9d6474de3919d0e157a7a043d","IPY_MODEL_f417fe0f56b1419eb393d4b9bb7cac4f","IPY_MODEL_7f2f18313a9b48a281b742f765eee68a"],"layout":"IPY_MODEL_abea09c7219b48e691287df0a2a8a689"}},"b39d9d4171aa4ac3901f3f565dbdedb9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_6412440adaf24a1f89385f50f3c27cbe","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae6a42abd7bc4251836976922330d02e","value":3}},"bcc6009bc67b4a5f9b24f67652690af5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bfa2aa1fffb7413096f5716dbc3fae9a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c8a31fb9dea4c709a25fcaf2bd7ccf2","placeholder":"​","style":"IPY_MODEL_bcc6009bc67b4a5f9b24f67652690af5","value":"100%"}},"c06b9f7f34e94b87bc7cc5d240b11623":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1bd319c1d394a3595a34a7c17adea07":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f75e0f5fcad947baa6353bf2b4fe81cb","IPY_MODEL_3dda6b69c20a43fa8166c6aef077b5d5","IPY_MODEL_8b3951c85bd74b668c3094c31029c72a"],"layout":"IPY_MODEL_ac5eb07253b746aba1d5e084fffc61ac"}},"c328272ecf8c476eb6beb8af43c7c88e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3ba56b10be24daf8601d5f765b11531":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9f00ac026fd4a4588f3aebf056607b3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc15cd85d45b4fd89db6397133faeee8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd65ae9aa2ce42beb252abf37a224fb6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cea5530aad974e379098d320bde565f8","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_56cd73ac22f9482c98c47ecfbc79fd22","value":2}},"cea5530aad974e379098d320bde565f8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2795d6eb6db498e843f36064a151496":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d4a9cd938011412fb7a36d5850f60056":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7061b0bbaf6458ca9518f3a67cb6fd1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d81b53cabf644fb888003bb5226b4b69":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"e108d8cfdce84a9386c60a57c0ccdc91":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e14ebba3c7024183aac18b2d61c280c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e30f6ce4fef949efaa11b06a6edc1a63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e37623fb7cbf4de5bfc4aede2aea8e68":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e40b957f198b48099a55d684cd6c4df5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e44553f939c2420f989debe0d85890c6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e96ccdf826914c908e4bd2c2d65097fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_687e9859f5054ac9965ce1fdfe10335f","placeholder":"​","style":"IPY_MODEL_1cc7e51154004f1c8ab939f2d519aa86","value":"Validation DataLoader 0: 100%"}},"ed58aa2dbf014ba397dd3dfc92748f4f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e44553f939c2420f989debe0d85890c6","placeholder":"​","style":"IPY_MODEL_d2795d6eb6db498e843f36064a151496","value":" 3/3 [00:01&lt;00:00,  2.30it/s, loss=2.58, v_num=0, val_loss=3.170]"}},"f417fe0f56b1419eb393d4b9bb7cac4f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_0aa8f40b4d974319ae78a03fcdd7ef05","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9e05266880874bc297ea8daff5b6d064","value":2}},"f75e0f5fcad947baa6353bf2b4fe81cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_557bbbf65f0447edae3f4275d9fdfcfd","placeholder":"​","style":"IPY_MODEL_52dc301529d647cd99743e227e964457","value":"Sanity Checking DataLoader 0: 100%"}},"f8382a174e324beaac03ccb096ed42b0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_aae1252dfd084067987adb777127fa83","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2f745a3b464d43d9970496fbaa96a9d5","value":2}},"fa3d9216d1a84191b7338946619a9769":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd2b69e1f33c457ea789eb9ae5a95951":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fe444eac38af4dd5b8854005db712bc7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
